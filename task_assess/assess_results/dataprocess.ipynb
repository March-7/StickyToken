{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = \"/root/StickyToken/task_assess/results/bge-base-en-v1.5_with_benign_tokens/no_model_name_available/no_revision_available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = os.listdir(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [task.removesuffix(\".json\") for task in task_list]\n",
    "# task_list = [\"BiorxivClusteringS2S\", \"MedrxivClusteringS2S\", \"TwentyNewsgroupsClustering\", \"SciFact\", \"ArguAna\", \"NFCorpus\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArguAna',\n",
       " 'Banking77Classification',\n",
       " 'BiorxivClusteringS2S',\n",
       " 'EmotionClassification',\n",
       " 'MassiveIntentClassification',\n",
       " 'MedrxivClusteringS2S',\n",
       " 'NFCorpus',\n",
       " 'SICK-R',\n",
       " 'STS16',\n",
       " 'STSBenchmark',\n",
       " 'SciDocsRR',\n",
       " 'SciFact',\n",
       " 'SprintDuplicateQuestions',\n",
       " 'StackOverflowDupQuestions',\n",
       " 'SummEval',\n",
       " 'TwentyNewsgroupsClustering',\n",
       " 'model_meta']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.listdir(\"./\")\n",
    "temp = [item for item in temp if os.path.isdir(item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GritLM-7B',\n",
       " 'GritLM-7B_with_benign_tokens',\n",
       " 'GritLM-7B_with_sticky_tokens',\n",
       " 'SFR-Embedding-2_R',\n",
       " 'SFR-Embedding-2_R_with_benign_tokens',\n",
       " 'SFR-Embedding-2_R_with_sticky_tokens',\n",
       " 'UAE-Large-V1',\n",
       " 'UAE-Large-V1_with_benign_tokens',\n",
       " 'UAE-Large-V1_with_sticky_tokens',\n",
       " 'all-mpnet-base-v2',\n",
       " 'all-mpnet-base-v2_with_benign_tokens',\n",
       " 'all-mpnet-base-v2_with_sticky_tokens',\n",
       " 'bge-base-en-v1.5',\n",
       " 'bge-base-en-v1.5_with_benign_tokens',\n",
       " 'bge-base-en-v1.5_with_sticky_tokens',\n",
       " 'e5-base',\n",
       " 'e5-base_with_benign_tokens',\n",
       " 'e5-base_with_sticky_tokens',\n",
       " 'e5-mistral-7b-instruct',\n",
       " 'e5-mistral-7b-instruct_with_benign_tokens',\n",
       " 'e5-mistral-7b-instruct_with_sticky_tokens',\n",
       " 'gte-Qwen2-7B-instruct',\n",
       " 'gte-Qwen2-7B-instruct_with_benign_tokens',\n",
       " 'gte-Qwen2-7B-instruct_with_sticky_tokens',\n",
       " 'gte-base-en-v1.5',\n",
       " 'gte-base-en-v1.5_with_benign_tokens',\n",
       " 'gte-base-en-v1.5_with_sticky_tokens',\n",
       " 'instructor-base',\n",
       " 'instructor-base_with_benign_tokens',\n",
       " 'instructor-base_with_sticky_tokens',\n",
       " 'sentence-t5-base',\n",
       " 'sentence-t5-base_with_benign_tokens',\n",
       " 'sentence-t5-base_with_sticky_tokens',\n",
       " 'sup-simcse-bert-base-uncased',\n",
       " 'sup-simcse-bert-base-uncased_with_benign_tokens',\n",
       " 'sup-simcse-bert-base-uncased_with_sticky_tokens']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = set([model.split(\"_with_\")[0] for model in temp])\n",
    "# model_set = {\n",
    "#  'e5-mistral-7b-instruct',\n",
    "#  'gte-Qwen2-7B-instruct',\n",
    "#  'GritLM-7B'\n",
    "#  }\n",
    "model_set = {'GritLM-7B',\n",
    " 'UAE-Large-V1',\n",
    " 'all-mpnet-base-v2',\n",
    " 'bge-base-en-v1.5',\n",
    " 'e5-base',\n",
    " 'e5-mistral-7b-instruct',\n",
    " 'gte-Qwen2-7B-instruct',\n",
    " 'gte-base-en-v1.5',\n",
    " 'instructor-base',\n",
    " 'sentence-t5-base',\n",
    " 'sup-simcse-bert-base-uncased'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GritLM-7B',\n",
       " 'UAE-Large-V1',\n",
       " 'all-mpnet-base-v2',\n",
       " 'bge-base-en-v1.5',\n",
       " 'e5-base',\n",
       " 'e5-mistral-7b-instruct',\n",
       " 'gte-Qwen2-7B-instruct',\n",
       " 'gte-base-en-v1.5',\n",
       " 'instructor-base',\n",
       " 'sentence-t5-base',\n",
       " 'sup-simcse-bert-base-uncased'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "result_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Banking77Classification',\n",
       " 'EmotionClassification',\n",
       " 'MassiveIntentClassification',\n",
       " 'BiorxivClusteringS2S',\n",
       " 'MedrxivClusteringS2S',\n",
       " 'TwentyNewsgroupsClustering',\n",
       " 'SprintDuplicateQuestions',\n",
       " 'StackOverflowDupQuestions',\n",
       " 'SciDocsRR',\n",
       " 'SciFact',\n",
       " 'ArguAna',\n",
       " 'NFCorpus',\n",
       " 'SICK-R',\n",
       " 'STS16',\n",
       " 'STSBenchmark',\n",
       " 'SummEval']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_list = \"Banking77Classification\tEmotionClassification\tMassiveIntentClassification\tBiorxivClusteringS2S\tMedrxivClusteringS2S\tTwentyNewsgroupsClustering\tSprintDuplicateQuestions\tStackOverflowDupQuestions\tSciDocsRR\tSciFact\tArguAna\tNFCorpus\tSICK-R\tSTS16\tSTSBenchmark\tSummEval\".split()\n",
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_list = [\"\", \"_with_benign_tokens\", \"_with_sticky_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_set:\n",
    "    for suffix in suffix_list:\n",
    "        if suffix == \"\":\n",
    "            result_dict[\"model\"].append(model)\n",
    "        elif \"sticky\" in suffix:\n",
    "            result_dict[\"model\"].append(\"w/ sticky oken\")\n",
    "        elif \"benign\" in suffix:\n",
    "            result_dict[\"model\"].append(\"w/ benign token\")\n",
    "        else:\n",
    "            print(\"error\")\n",
    "            continue\n",
    "        \n",
    "        scores = []\n",
    "        for task in task_list:\n",
    "            try:\n",
    "                with open(f\"{model}{suffix}/no_model_name_available/no_revision_available/{task}.json\") as f:\n",
    "                    data = json.load(f)\n",
    "                score = data[\"scores\"][\"test\"][0][\"main_score\"]\n",
    "                result_dict[task].append(score)\n",
    "                scores.append(score)\n",
    "            except:\n",
    "                result_dict[task].append(np.nan)\n",
    "                scores.append(np.nan)\n",
    "        \n",
    "        # 计算并添加average列\n",
    "        valid_scores = [s for s in scores if not np.isnan(s)]\n",
    "        avg_score = np.mean(valid_scores) if valid_scores else np.nan\n",
    "        result_dict[\"Avarage\"].append(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Banking77Classification</th>\n",
       "      <th>EmotionClassification</th>\n",
       "      <th>MassiveIntentClassification</th>\n",
       "      <th>BiorxivClusteringS2S</th>\n",
       "      <th>MedrxivClusteringS2S</th>\n",
       "      <th>TwentyNewsgroupsClustering</th>\n",
       "      <th>SprintDuplicateQuestions</th>\n",
       "      <th>StackOverflowDupQuestions</th>\n",
       "      <th>SciDocsRR</th>\n",
       "      <th>SciFact</th>\n",
       "      <th>ArguAna</th>\n",
       "      <th>NFCorpus</th>\n",
       "      <th>SICK-R</th>\n",
       "      <th>STS16</th>\n",
       "      <th>STSBenchmark</th>\n",
       "      <th>SummEval</th>\n",
       "      <th>Avarage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>0.839903</td>\n",
       "      <td>0.54605</td>\n",
       "      <td>0.726362</td>\n",
       "      <td>0.366180</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>0.507540</td>\n",
       "      <td>0.963707</td>\n",
       "      <td>0.546166</td>\n",
       "      <td>0.874941</td>\n",
       "      <td>0.73763</td>\n",
       "      <td>0.63616</td>\n",
       "      <td>0.36810</td>\n",
       "      <td>0.803011</td>\n",
       "      <td>0.854741</td>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.310384</td>\n",
       "      <td>0.641365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.825747</td>\n",
       "      <td>0.52700</td>\n",
       "      <td>0.669839</td>\n",
       "      <td>0.362037</td>\n",
       "      <td>0.307375</td>\n",
       "      <td>0.442676</td>\n",
       "      <td>0.951759</td>\n",
       "      <td>0.509383</td>\n",
       "      <td>0.865869</td>\n",
       "      <td>0.72909</td>\n",
       "      <td>0.60633</td>\n",
       "      <td>0.37154</td>\n",
       "      <td>0.761022</td>\n",
       "      <td>0.809686</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.299657</td>\n",
       "      <td>0.616198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.823084</td>\n",
       "      <td>0.51980</td>\n",
       "      <td>0.676194</td>\n",
       "      <td>0.359285</td>\n",
       "      <td>0.310602</td>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.949535</td>\n",
       "      <td>0.509884</td>\n",
       "      <td>0.866086</td>\n",
       "      <td>0.73702</td>\n",
       "      <td>0.61314</td>\n",
       "      <td>0.37055</td>\n",
       "      <td>0.778028</td>\n",
       "      <td>0.801143</td>\n",
       "      <td>0.817223</td>\n",
       "      <td>0.303052</td>\n",
       "      <td>0.616765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gte-Qwen2-7B-instruct</td>\n",
       "      <td>0.839968</td>\n",
       "      <td>0.55285</td>\n",
       "      <td>0.774647</td>\n",
       "      <td>0.391576</td>\n",
       "      <td>0.333379</td>\n",
       "      <td>0.523434</td>\n",
       "      <td>0.931263</td>\n",
       "      <td>0.528654</td>\n",
       "      <td>0.862513</td>\n",
       "      <td>0.79546</td>\n",
       "      <td>0.64708</td>\n",
       "      <td>0.40332</td>\n",
       "      <td>0.780605</td>\n",
       "      <td>0.828209</td>\n",
       "      <td>0.816060</td>\n",
       "      <td>0.304621</td>\n",
       "      <td>0.644602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.828896</td>\n",
       "      <td>0.54430</td>\n",
       "      <td>0.740585</td>\n",
       "      <td>0.380455</td>\n",
       "      <td>0.326690</td>\n",
       "      <td>0.483500</td>\n",
       "      <td>0.930777</td>\n",
       "      <td>0.493868</td>\n",
       "      <td>0.856585</td>\n",
       "      <td>0.79677</td>\n",
       "      <td>0.63661</td>\n",
       "      <td>0.40594</td>\n",
       "      <td>0.717877</td>\n",
       "      <td>0.742354</td>\n",
       "      <td>0.723021</td>\n",
       "      <td>0.299455</td>\n",
       "      <td>0.619230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.814773</td>\n",
       "      <td>0.53215</td>\n",
       "      <td>0.728447</td>\n",
       "      <td>0.327726</td>\n",
       "      <td>0.296437</td>\n",
       "      <td>0.474965</td>\n",
       "      <td>0.866880</td>\n",
       "      <td>0.434027</td>\n",
       "      <td>0.814856</td>\n",
       "      <td>0.72605</td>\n",
       "      <td>0.55030</td>\n",
       "      <td>0.34452</td>\n",
       "      <td>0.627502</td>\n",
       "      <td>0.716853</td>\n",
       "      <td>0.668144</td>\n",
       "      <td>0.283759</td>\n",
       "      <td>0.575462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>0.762662</td>\n",
       "      <td>0.51850</td>\n",
       "      <td>0.666543</td>\n",
       "      <td>0.299163</td>\n",
       "      <td>0.276719</td>\n",
       "      <td>0.437485</td>\n",
       "      <td>0.941856</td>\n",
       "      <td>0.481834</td>\n",
       "      <td>0.810134</td>\n",
       "      <td>0.71880</td>\n",
       "      <td>0.53033</td>\n",
       "      <td>0.37087</td>\n",
       "      <td>0.806585</td>\n",
       "      <td>0.844863</td>\n",
       "      <td>0.863475</td>\n",
       "      <td>0.310448</td>\n",
       "      <td>0.602517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.748539</td>\n",
       "      <td>0.49910</td>\n",
       "      <td>0.630027</td>\n",
       "      <td>0.289443</td>\n",
       "      <td>0.265082</td>\n",
       "      <td>0.221486</td>\n",
       "      <td>0.913664</td>\n",
       "      <td>0.441079</td>\n",
       "      <td>0.798544</td>\n",
       "      <td>0.71355</td>\n",
       "      <td>0.51130</td>\n",
       "      <td>0.37150</td>\n",
       "      <td>0.760070</td>\n",
       "      <td>0.781713</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>0.307588</td>\n",
       "      <td>0.565433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.751266</td>\n",
       "      <td>0.49305</td>\n",
       "      <td>0.619132</td>\n",
       "      <td>0.270223</td>\n",
       "      <td>0.249217</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>0.915302</td>\n",
       "      <td>0.448004</td>\n",
       "      <td>0.800319</td>\n",
       "      <td>0.70948</td>\n",
       "      <td>0.49142</td>\n",
       "      <td>0.37011</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>0.776764</td>\n",
       "      <td>0.801895</td>\n",
       "      <td>0.299889</td>\n",
       "      <td>0.560489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e5-mistral-7b-instruct</td>\n",
       "      <td>0.785974</td>\n",
       "      <td>0.48415</td>\n",
       "      <td>0.711466</td>\n",
       "      <td>0.344725</td>\n",
       "      <td>0.322914</td>\n",
       "      <td>0.473055</td>\n",
       "      <td>0.898825</td>\n",
       "      <td>0.465613</td>\n",
       "      <td>0.820873</td>\n",
       "      <td>0.75176</td>\n",
       "      <td>0.53879</td>\n",
       "      <td>0.33263</td>\n",
       "      <td>0.807579</td>\n",
       "      <td>0.848295</td>\n",
       "      <td>0.845862</td>\n",
       "      <td>0.310729</td>\n",
       "      <td>0.608953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.775584</td>\n",
       "      <td>0.46930</td>\n",
       "      <td>0.687256</td>\n",
       "      <td>0.318480</td>\n",
       "      <td>0.303218</td>\n",
       "      <td>0.448419</td>\n",
       "      <td>0.891020</td>\n",
       "      <td>0.451517</td>\n",
       "      <td>0.807743</td>\n",
       "      <td>0.74711</td>\n",
       "      <td>0.54182</td>\n",
       "      <td>0.34569</td>\n",
       "      <td>0.791305</td>\n",
       "      <td>0.793041</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>0.301451</td>\n",
       "      <td>0.592855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.749513</td>\n",
       "      <td>0.40165</td>\n",
       "      <td>0.653241</td>\n",
       "      <td>0.289224</td>\n",
       "      <td>0.283719</td>\n",
       "      <td>0.407779</td>\n",
       "      <td>0.805672</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.790716</td>\n",
       "      <td>0.72213</td>\n",
       "      <td>0.55298</td>\n",
       "      <td>0.33172</td>\n",
       "      <td>0.748464</td>\n",
       "      <td>0.740841</td>\n",
       "      <td>0.674609</td>\n",
       "      <td>0.271464</td>\n",
       "      <td>0.552114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>0.817013</td>\n",
       "      <td>0.42225</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.348199</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>0.500655</td>\n",
       "      <td>0.901455</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.886540</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.46521</td>\n",
       "      <td>0.33289</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.800301</td>\n",
       "      <td>0.834219</td>\n",
       "      <td>0.274859</td>\n",
       "      <td>0.599794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.797013</td>\n",
       "      <td>0.40010</td>\n",
       "      <td>0.640989</td>\n",
       "      <td>0.339270</td>\n",
       "      <td>0.325532</td>\n",
       "      <td>0.392039</td>\n",
       "      <td>0.862363</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.877669</td>\n",
       "      <td>0.65138</td>\n",
       "      <td>0.44247</td>\n",
       "      <td>0.33196</td>\n",
       "      <td>0.777985</td>\n",
       "      <td>0.681311</td>\n",
       "      <td>0.741146</td>\n",
       "      <td>0.282988</td>\n",
       "      <td>0.563597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.796396</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.650168</td>\n",
       "      <td>0.340461</td>\n",
       "      <td>0.321565</td>\n",
       "      <td>0.392844</td>\n",
       "      <td>0.858719</td>\n",
       "      <td>0.477901</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.64806</td>\n",
       "      <td>0.43979</td>\n",
       "      <td>0.33158</td>\n",
       "      <td>0.780371</td>\n",
       "      <td>0.681960</td>\n",
       "      <td>0.731903</td>\n",
       "      <td>0.261737</td>\n",
       "      <td>0.562353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gte-base-en-v1.5</td>\n",
       "      <td>0.867175</td>\n",
       "      <td>0.46335</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.373946</td>\n",
       "      <td>0.323055</td>\n",
       "      <td>0.486565</td>\n",
       "      <td>0.950349</td>\n",
       "      <td>0.521759</td>\n",
       "      <td>0.851639</td>\n",
       "      <td>0.76792</td>\n",
       "      <td>0.63648</td>\n",
       "      <td>0.35848</td>\n",
       "      <td>0.793815</td>\n",
       "      <td>0.850244</td>\n",
       "      <td>0.860643</td>\n",
       "      <td>0.313472</td>\n",
       "      <td>0.637222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.846169</td>\n",
       "      <td>0.44385</td>\n",
       "      <td>0.710323</td>\n",
       "      <td>0.356268</td>\n",
       "      <td>0.307785</td>\n",
       "      <td>0.265138</td>\n",
       "      <td>0.905495</td>\n",
       "      <td>0.472815</td>\n",
       "      <td>0.839498</td>\n",
       "      <td>0.75442</td>\n",
       "      <td>0.61662</td>\n",
       "      <td>0.35544</td>\n",
       "      <td>0.752260</td>\n",
       "      <td>0.781319</td>\n",
       "      <td>0.797114</td>\n",
       "      <td>0.296075</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.858701</td>\n",
       "      <td>0.46100</td>\n",
       "      <td>0.749159</td>\n",
       "      <td>0.363070</td>\n",
       "      <td>0.320069</td>\n",
       "      <td>0.446836</td>\n",
       "      <td>0.941943</td>\n",
       "      <td>0.499956</td>\n",
       "      <td>0.846739</td>\n",
       "      <td>0.73364</td>\n",
       "      <td>0.62139</td>\n",
       "      <td>0.35217</td>\n",
       "      <td>0.773593</td>\n",
       "      <td>0.817487</td>\n",
       "      <td>0.836534</td>\n",
       "      <td>0.318684</td>\n",
       "      <td>0.621311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>instructor-base</td>\n",
       "      <td>0.769156</td>\n",
       "      <td>0.48480</td>\n",
       "      <td>0.659953</td>\n",
       "      <td>0.264031</td>\n",
       "      <td>0.283780</td>\n",
       "      <td>0.527689</td>\n",
       "      <td>0.920578</td>\n",
       "      <td>0.506645</td>\n",
       "      <td>0.793603</td>\n",
       "      <td>0.57883</td>\n",
       "      <td>0.51176</td>\n",
       "      <td>0.30757</td>\n",
       "      <td>0.800247</td>\n",
       "      <td>0.847774</td>\n",
       "      <td>0.858482</td>\n",
       "      <td>0.305743</td>\n",
       "      <td>0.588790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.750714</td>\n",
       "      <td>0.45790</td>\n",
       "      <td>0.623806</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>0.286438</td>\n",
       "      <td>0.883939</td>\n",
       "      <td>0.476635</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>0.57702</td>\n",
       "      <td>0.47446</td>\n",
       "      <td>0.29770</td>\n",
       "      <td>0.754825</td>\n",
       "      <td>0.779680</td>\n",
       "      <td>0.799894</td>\n",
       "      <td>0.303668</td>\n",
       "      <td>0.541109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.763734</td>\n",
       "      <td>0.47665</td>\n",
       "      <td>0.646167</td>\n",
       "      <td>0.260460</td>\n",
       "      <td>0.265516</td>\n",
       "      <td>0.505472</td>\n",
       "      <td>0.912965</td>\n",
       "      <td>0.496660</td>\n",
       "      <td>0.766260</td>\n",
       "      <td>0.43471</td>\n",
       "      <td>0.47030</td>\n",
       "      <td>0.23106</td>\n",
       "      <td>0.788639</td>\n",
       "      <td>0.819561</td>\n",
       "      <td>0.842066</td>\n",
       "      <td>0.291665</td>\n",
       "      <td>0.560743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence-t5-base</td>\n",
       "      <td>0.766039</td>\n",
       "      <td>0.51340</td>\n",
       "      <td>0.696974</td>\n",
       "      <td>0.231079</td>\n",
       "      <td>0.260272</td>\n",
       "      <td>0.492733</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.484637</td>\n",
       "      <td>0.739623</td>\n",
       "      <td>0.45760</td>\n",
       "      <td>0.44844</td>\n",
       "      <td>0.28645</td>\n",
       "      <td>0.801823</td>\n",
       "      <td>0.840323</td>\n",
       "      <td>0.855203</td>\n",
       "      <td>0.313910</td>\n",
       "      <td>0.568799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.757273</td>\n",
       "      <td>0.51305</td>\n",
       "      <td>0.665669</td>\n",
       "      <td>0.200376</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.371668</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.448502</td>\n",
       "      <td>0.720505</td>\n",
       "      <td>0.44580</td>\n",
       "      <td>0.45411</td>\n",
       "      <td>0.28485</td>\n",
       "      <td>0.767207</td>\n",
       "      <td>0.796880</td>\n",
       "      <td>0.813157</td>\n",
       "      <td>0.303225</td>\n",
       "      <td>0.541968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.752013</td>\n",
       "      <td>0.50195</td>\n",
       "      <td>0.668325</td>\n",
       "      <td>0.150215</td>\n",
       "      <td>0.204122</td>\n",
       "      <td>0.353841</td>\n",
       "      <td>0.883928</td>\n",
       "      <td>0.451617</td>\n",
       "      <td>0.711696</td>\n",
       "      <td>0.26757</td>\n",
       "      <td>0.42141</td>\n",
       "      <td>0.13650</td>\n",
       "      <td>0.763194</td>\n",
       "      <td>0.792624</td>\n",
       "      <td>0.812406</td>\n",
       "      <td>0.308402</td>\n",
       "      <td>0.511238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UAE-Large-V1</td>\n",
       "      <td>0.877305</td>\n",
       "      <td>0.51720</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.372365</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.517155</td>\n",
       "      <td>0.972370</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.874908</td>\n",
       "      <td>0.73909</td>\n",
       "      <td>0.66150</td>\n",
       "      <td>0.37609</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.890608</td>\n",
       "      <td>0.320291</td>\n",
       "      <td>0.652415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.860909</td>\n",
       "      <td>0.48165</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>0.357911</td>\n",
       "      <td>0.309552</td>\n",
       "      <td>0.404801</td>\n",
       "      <td>0.962295</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.867492</td>\n",
       "      <td>0.74513</td>\n",
       "      <td>0.63666</td>\n",
       "      <td>0.37703</td>\n",
       "      <td>0.807150</td>\n",
       "      <td>0.804317</td>\n",
       "      <td>0.842266</td>\n",
       "      <td>0.319858</td>\n",
       "      <td>0.625173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.865584</td>\n",
       "      <td>0.50430</td>\n",
       "      <td>0.727875</td>\n",
       "      <td>0.359789</td>\n",
       "      <td>0.309371</td>\n",
       "      <td>0.471986</td>\n",
       "      <td>0.965171</td>\n",
       "      <td>0.524402</td>\n",
       "      <td>0.869359</td>\n",
       "      <td>0.72634</td>\n",
       "      <td>0.63482</td>\n",
       "      <td>0.37791</td>\n",
       "      <td>0.815291</td>\n",
       "      <td>0.831341</td>\n",
       "      <td>0.859991</td>\n",
       "      <td>0.308443</td>\n",
       "      <td>0.634498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GritLM-7B</td>\n",
       "      <td>0.704383</td>\n",
       "      <td>0.36030</td>\n",
       "      <td>0.628951</td>\n",
       "      <td>0.236651</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>0.195719</td>\n",
       "      <td>0.585805</td>\n",
       "      <td>0.355647</td>\n",
       "      <td>0.600536</td>\n",
       "      <td>0.44574</td>\n",
       "      <td>0.37327</td>\n",
       "      <td>0.06994</td>\n",
       "      <td>0.580679</td>\n",
       "      <td>0.576050</td>\n",
       "      <td>0.483235</td>\n",
       "      <td>0.241094</td>\n",
       "      <td>0.417457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.620487</td>\n",
       "      <td>0.35130</td>\n",
       "      <td>0.567451</td>\n",
       "      <td>0.147494</td>\n",
       "      <td>0.188034</td>\n",
       "      <td>0.109395</td>\n",
       "      <td>0.444477</td>\n",
       "      <td>0.298582</td>\n",
       "      <td>0.538960</td>\n",
       "      <td>0.39521</td>\n",
       "      <td>0.33609</td>\n",
       "      <td>0.06252</td>\n",
       "      <td>0.276886</td>\n",
       "      <td>0.320737</td>\n",
       "      <td>0.272921</td>\n",
       "      <td>0.257994</td>\n",
       "      <td>0.324284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.564156</td>\n",
       "      <td>0.34910</td>\n",
       "      <td>0.493645</td>\n",
       "      <td>0.194075</td>\n",
       "      <td>0.158250</td>\n",
       "      <td>0.100444</td>\n",
       "      <td>0.407264</td>\n",
       "      <td>0.261767</td>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.36411</td>\n",
       "      <td>0.29728</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>0.266369</td>\n",
       "      <td>0.410437</td>\n",
       "      <td>0.236894</td>\n",
       "      <td>0.228127</td>\n",
       "      <td>0.305199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sup-simcse-bert-base-uncased</td>\n",
       "      <td>0.754870</td>\n",
       "      <td>0.45690</td>\n",
       "      <td>0.672058</td>\n",
       "      <td>0.257039</td>\n",
       "      <td>0.258510</td>\n",
       "      <td>0.316721</td>\n",
       "      <td>0.817385</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.711449</td>\n",
       "      <td>0.33889</td>\n",
       "      <td>0.39556</td>\n",
       "      <td>0.13487</td>\n",
       "      <td>0.806244</td>\n",
       "      <td>0.807146</td>\n",
       "      <td>0.826862</td>\n",
       "      <td>0.311741</td>\n",
       "      <td>0.516840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.714221</td>\n",
       "      <td>0.43490</td>\n",
       "      <td>0.603833</td>\n",
       "      <td>0.251126</td>\n",
       "      <td>0.251914</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.765369</td>\n",
       "      <td>0.373431</td>\n",
       "      <td>0.700181</td>\n",
       "      <td>0.33656</td>\n",
       "      <td>0.36787</td>\n",
       "      <td>0.13446</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.758212</td>\n",
       "      <td>0.783215</td>\n",
       "      <td>0.307569</td>\n",
       "      <td>0.490137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.43345</td>\n",
       "      <td>0.610256</td>\n",
       "      <td>0.247981</td>\n",
       "      <td>0.251733</td>\n",
       "      <td>0.292178</td>\n",
       "      <td>0.765093</td>\n",
       "      <td>0.383072</td>\n",
       "      <td>0.702481</td>\n",
       "      <td>0.29886</td>\n",
       "      <td>0.38384</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.777372</td>\n",
       "      <td>0.770455</td>\n",
       "      <td>0.795337</td>\n",
       "      <td>0.301765</td>\n",
       "      <td>0.489142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  Banking77Classification  \\\n",
       "0               bge-base-en-v1.5                 0.839903   \n",
       "1                w/ benign token                 0.825747   \n",
       "2                 w/ sticky oken                 0.823084   \n",
       "3          gte-Qwen2-7B-instruct                 0.839968   \n",
       "4                w/ benign token                 0.828896   \n",
       "5                 w/ sticky oken                 0.814773   \n",
       "6                        e5-base                 0.762662   \n",
       "7                w/ benign token                 0.748539   \n",
       "8                 w/ sticky oken                 0.751266   \n",
       "9         e5-mistral-7b-instruct                 0.785974   \n",
       "10               w/ benign token                 0.775584   \n",
       "11                w/ sticky oken                 0.749513   \n",
       "12             all-mpnet-base-v2                 0.817013   \n",
       "13               w/ benign token                 0.797013   \n",
       "14                w/ sticky oken                 0.796396   \n",
       "15              gte-base-en-v1.5                 0.867175   \n",
       "16               w/ benign token                 0.846169   \n",
       "17                w/ sticky oken                 0.858701   \n",
       "18               instructor-base                 0.769156   \n",
       "19               w/ benign token                 0.750714   \n",
       "20                w/ sticky oken                 0.763734   \n",
       "21              sentence-t5-base                 0.766039   \n",
       "22               w/ benign token                 0.757273   \n",
       "23                w/ sticky oken                 0.752013   \n",
       "24                  UAE-Large-V1                 0.877305   \n",
       "25               w/ benign token                 0.860909   \n",
       "26                w/ sticky oken                 0.865584   \n",
       "27                     GritLM-7B                 0.704383   \n",
       "28               w/ benign token                 0.620487   \n",
       "29                w/ sticky oken                 0.564156   \n",
       "30  sup-simcse-bert-base-uncased                 0.754870   \n",
       "31               w/ benign token                 0.714221   \n",
       "32                w/ sticky oken                 0.724026   \n",
       "\n",
       "    EmotionClassification  MassiveIntentClassification  BiorxivClusteringS2S  \\\n",
       "0                 0.54605                     0.726362              0.366180   \n",
       "1                 0.52700                     0.669839              0.362037   \n",
       "2                 0.51980                     0.676194              0.359285   \n",
       "3                 0.55285                     0.774647              0.391576   \n",
       "4                 0.54430                     0.740585              0.380455   \n",
       "5                 0.53215                     0.728447              0.327726   \n",
       "6                 0.51850                     0.666543              0.299163   \n",
       "7                 0.49910                     0.630027              0.289443   \n",
       "8                 0.49305                     0.619132              0.270223   \n",
       "9                 0.48415                     0.711466              0.344725   \n",
       "10                0.46930                     0.687256              0.318480   \n",
       "11                0.40165                     0.653241              0.289224   \n",
       "12                0.42225                     0.697579              0.348199   \n",
       "13                0.40010                     0.640989              0.339270   \n",
       "14                0.40650                     0.650168              0.340461   \n",
       "15                0.46335                     0.776664              0.373946   \n",
       "16                0.44385                     0.710323              0.356268   \n",
       "17                0.46100                     0.749159              0.363070   \n",
       "18                0.48480                     0.659953              0.264031   \n",
       "19                0.45790                     0.623806              0.180528   \n",
       "20                0.47665                     0.646167              0.260460   \n",
       "21                0.51340                     0.696974              0.231079   \n",
       "22                0.51305                     0.665669              0.200376   \n",
       "23                0.50195                     0.668325              0.150215   \n",
       "24                0.51720                     0.762408              0.372365   \n",
       "25                0.48165                     0.721318              0.357911   \n",
       "26                0.50430                     0.727875              0.359789   \n",
       "27                0.36030                     0.628951              0.236651   \n",
       "28                0.35130                     0.567451              0.147494   \n",
       "29                0.34910                     0.493645              0.194075   \n",
       "30                0.45690                     0.672058              0.257039   \n",
       "31                0.43490                     0.603833              0.251126   \n",
       "32                0.43345                     0.610256              0.247981   \n",
       "\n",
       "    MedrxivClusteringS2S  TwentyNewsgroupsClustering  \\\n",
       "0               0.316789                    0.507540   \n",
       "1               0.307375                    0.442676   \n",
       "2               0.310602                    0.433612   \n",
       "3               0.333379                    0.523434   \n",
       "4               0.326690                    0.483500   \n",
       "5               0.296437                    0.474965   \n",
       "6               0.276719                    0.437485   \n",
       "7               0.265082                    0.221486   \n",
       "8               0.249217                    0.200038   \n",
       "9               0.322914                    0.473055   \n",
       "10              0.303218                    0.448419   \n",
       "11              0.283719                    0.407779   \n",
       "12              0.334190                    0.500655   \n",
       "13              0.325532                    0.392039   \n",
       "14              0.321565                    0.392844   \n",
       "15              0.323055                    0.486565   \n",
       "16              0.307785                    0.265138   \n",
       "17              0.320069                    0.446836   \n",
       "18              0.283780                    0.527689   \n",
       "19              0.231340                    0.286438   \n",
       "20              0.265516                    0.505472   \n",
       "21              0.260272                    0.492733   \n",
       "22              0.250571                    0.371668   \n",
       "23              0.204122                    0.353841   \n",
       "24              0.311805                    0.517155   \n",
       "25              0.309552                    0.404801   \n",
       "26              0.309371                    0.471986   \n",
       "27              0.241314                    0.195719   \n",
       "28              0.188034                    0.109395   \n",
       "29              0.158250                    0.100444   \n",
       "30              0.258510                    0.316721   \n",
       "31              0.251914                    0.284020   \n",
       "32              0.251733                    0.292178   \n",
       "\n",
       "    SprintDuplicateQuestions  StackOverflowDupQuestions  SciDocsRR  SciFact  \\\n",
       "0                   0.963707                   0.546166   0.874941  0.73763   \n",
       "1                   0.951759                   0.509383   0.865869  0.72909   \n",
       "2                   0.949535                   0.509884   0.866086  0.73702   \n",
       "3                   0.931263                   0.528654   0.862513  0.79546   \n",
       "4                   0.930777                   0.493868   0.856585  0.79677   \n",
       "5                   0.866880                   0.434027   0.814856  0.72605   \n",
       "6                   0.941856                   0.481834   0.810134  0.71880   \n",
       "7                   0.913664                   0.441079   0.798544  0.71355   \n",
       "8                   0.915302                   0.448004   0.800319  0.70948   \n",
       "9                   0.898825                   0.465613   0.820873  0.75176   \n",
       "10                  0.891020                   0.451517   0.807743  0.74711   \n",
       "11                  0.805672                   0.410100   0.790716  0.72213   \n",
       "12                  0.901455                   0.519791   0.886540  0.65570   \n",
       "13                  0.862363                   0.473333   0.877669  0.65138   \n",
       "14                  0.858719                   0.477901   0.877694  0.64806   \n",
       "15                  0.950349                   0.521759   0.851639  0.76792   \n",
       "16                  0.905495                   0.472815   0.839498  0.75442   \n",
       "17                  0.941943                   0.499956   0.846739  0.73364   \n",
       "18                  0.920578                   0.506645   0.793603  0.57883   \n",
       "19                  0.883939                   0.476635   0.779199  0.57702   \n",
       "20                  0.912965                   0.496660   0.766260  0.43471   \n",
       "21                  0.912281                   0.484637   0.739623  0.45760   \n",
       "22                  0.878646                   0.448502   0.720505  0.44580   \n",
       "23                  0.883928                   0.451617   0.711696  0.26757   \n",
       "24                  0.972370                   0.553200   0.874908  0.73909   \n",
       "25                  0.962295                   0.504425   0.867492  0.74513   \n",
       "26                  0.965171                   0.524402   0.869359  0.72634   \n",
       "27                  0.585805                   0.355647   0.600536  0.44574   \n",
       "28                  0.444477                   0.298582   0.538960  0.39521   \n",
       "29                  0.407264                   0.261767   0.489333  0.36411   \n",
       "30                  0.817385                   0.403188   0.711449  0.33889   \n",
       "31                  0.765369                   0.373431   0.700181  0.33656   \n",
       "32                  0.765093                   0.383072   0.702481  0.29886   \n",
       "\n",
       "    ArguAna  NFCorpus    SICK-R     STS16  STSBenchmark  SummEval   Avarage  \n",
       "0   0.63616   0.36810  0.803011  0.854741      0.864180  0.310384  0.641365  \n",
       "1   0.60633   0.37154  0.761022  0.809686      0.820162  0.299657  0.616198  \n",
       "2   0.61314   0.37055  0.778028  0.801143      0.817223  0.303052  0.616765  \n",
       "3   0.64708   0.40332  0.780605  0.828209      0.816060  0.304621  0.644602  \n",
       "4   0.63661   0.40594  0.717877  0.742354      0.723021  0.299455  0.619230  \n",
       "5   0.55030   0.34452  0.627502  0.716853      0.668144  0.283759  0.575462  \n",
       "6   0.53033   0.37087  0.806585  0.844863      0.863475  0.310448  0.602517  \n",
       "7   0.51130   0.37150  0.760070  0.781713      0.794241  0.307588  0.565433  \n",
       "8   0.49142   0.37011  0.771711  0.776764      0.801895  0.299889  0.560489  \n",
       "9   0.53879   0.33263  0.807579  0.848295      0.845862  0.310729  0.608953  \n",
       "10  0.54182   0.34569  0.791305  0.793041      0.812724  0.301451  0.592855  \n",
       "11  0.55298   0.33172  0.748464  0.740841      0.674609  0.271464  0.552114  \n",
       "12  0.46521   0.33289  0.805854  0.800301      0.834219  0.274859  0.599794  \n",
       "13  0.44247   0.33196  0.777985  0.681311      0.741146  0.282988  0.563597  \n",
       "14  0.43979   0.33158  0.780371  0.681960      0.731903  0.261737  0.562353  \n",
       "15  0.63648   0.35848  0.793815  0.850244      0.860643  0.313472  0.637222  \n",
       "16  0.61662   0.35544  0.752260  0.781319      0.797114  0.296075  0.593787  \n",
       "17  0.62139   0.35217  0.773593  0.817487      0.836534  0.318684  0.621311  \n",
       "18  0.51176   0.30757  0.800247  0.847774      0.858482  0.305743  0.588790  \n",
       "19  0.47446   0.29770  0.754825  0.779680      0.799894  0.303668  0.541109  \n",
       "20  0.47030   0.23106  0.788639  0.819561      0.842066  0.291665  0.560743  \n",
       "21  0.44844   0.28645  0.801823  0.840323      0.855203  0.313910  0.568799  \n",
       "22  0.45411   0.28485  0.767207  0.796880      0.813157  0.303225  0.541968  \n",
       "23  0.42141   0.13650  0.763194  0.792624      0.812406  0.308402  0.511238  \n",
       "24  0.66150   0.37609  0.826233  0.866117      0.890608  0.320291  0.652415  \n",
       "25  0.63666   0.37703  0.807150  0.804317      0.842266  0.319858  0.625173  \n",
       "26  0.63482   0.37791  0.815291  0.831341      0.859991  0.308443  0.634498  \n",
       "27  0.37327   0.06994  0.580679  0.576050      0.483235  0.241094  0.417457  \n",
       "28  0.33609   0.06252  0.276886  0.320737      0.272921  0.257994  0.324284  \n",
       "29  0.29728   0.06194  0.266369  0.410437      0.236894  0.228127  0.305199  \n",
       "30  0.39556   0.13487  0.806244  0.807146      0.826862  0.311741  0.516840  \n",
       "31  0.36787   0.13446  0.775304  0.758212      0.783215  0.307569  0.490137  \n",
       "32  0.38384   0.08837  0.777372  0.770455      0.795337  0.301765  0.489142  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd = pd.DataFrame(result_dict)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3833/2289510975.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  result_pd.iloc[:, 1:] = result_pd.iloc[:, 1:].applymap(lambda x: round(x * 100, 2) if pd.notnull(x) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Banking77Classification</th>\n",
       "      <th>EmotionClassification</th>\n",
       "      <th>MassiveIntentClassification</th>\n",
       "      <th>BiorxivClusteringS2S</th>\n",
       "      <th>MedrxivClusteringS2S</th>\n",
       "      <th>TwentyNewsgroupsClustering</th>\n",
       "      <th>SprintDuplicateQuestions</th>\n",
       "      <th>StackOverflowDupQuestions</th>\n",
       "      <th>SciDocsRR</th>\n",
       "      <th>SciFact</th>\n",
       "      <th>ArguAna</th>\n",
       "      <th>NFCorpus</th>\n",
       "      <th>SICK-R</th>\n",
       "      <th>STS16</th>\n",
       "      <th>STSBenchmark</th>\n",
       "      <th>SummEval</th>\n",
       "      <th>Avarage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>83.99</td>\n",
       "      <td>54.61</td>\n",
       "      <td>72.64</td>\n",
       "      <td>36.62</td>\n",
       "      <td>31.68</td>\n",
       "      <td>50.75</td>\n",
       "      <td>96.37</td>\n",
       "      <td>54.62</td>\n",
       "      <td>87.49</td>\n",
       "      <td>73.76</td>\n",
       "      <td>63.62</td>\n",
       "      <td>36.81</td>\n",
       "      <td>80.30</td>\n",
       "      <td>85.47</td>\n",
       "      <td>86.42</td>\n",
       "      <td>31.04</td>\n",
       "      <td>64.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>82.57</td>\n",
       "      <td>52.70</td>\n",
       "      <td>66.98</td>\n",
       "      <td>36.20</td>\n",
       "      <td>30.74</td>\n",
       "      <td>44.27</td>\n",
       "      <td>95.18</td>\n",
       "      <td>50.94</td>\n",
       "      <td>86.59</td>\n",
       "      <td>72.91</td>\n",
       "      <td>60.63</td>\n",
       "      <td>37.15</td>\n",
       "      <td>76.10</td>\n",
       "      <td>80.97</td>\n",
       "      <td>82.02</td>\n",
       "      <td>29.97</td>\n",
       "      <td>61.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>82.31</td>\n",
       "      <td>51.98</td>\n",
       "      <td>67.62</td>\n",
       "      <td>35.93</td>\n",
       "      <td>31.06</td>\n",
       "      <td>43.36</td>\n",
       "      <td>94.95</td>\n",
       "      <td>50.99</td>\n",
       "      <td>86.61</td>\n",
       "      <td>73.70</td>\n",
       "      <td>61.31</td>\n",
       "      <td>37.05</td>\n",
       "      <td>77.80</td>\n",
       "      <td>80.11</td>\n",
       "      <td>81.72</td>\n",
       "      <td>30.31</td>\n",
       "      <td>61.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gte-Qwen2-7B-instruct</td>\n",
       "      <td>84.00</td>\n",
       "      <td>55.28</td>\n",
       "      <td>77.46</td>\n",
       "      <td>39.16</td>\n",
       "      <td>33.34</td>\n",
       "      <td>52.34</td>\n",
       "      <td>93.13</td>\n",
       "      <td>52.87</td>\n",
       "      <td>86.25</td>\n",
       "      <td>79.55</td>\n",
       "      <td>64.71</td>\n",
       "      <td>40.33</td>\n",
       "      <td>78.06</td>\n",
       "      <td>82.82</td>\n",
       "      <td>81.61</td>\n",
       "      <td>30.46</td>\n",
       "      <td>64.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>82.89</td>\n",
       "      <td>54.43</td>\n",
       "      <td>74.06</td>\n",
       "      <td>38.05</td>\n",
       "      <td>32.67</td>\n",
       "      <td>48.35</td>\n",
       "      <td>93.08</td>\n",
       "      <td>49.39</td>\n",
       "      <td>85.66</td>\n",
       "      <td>79.68</td>\n",
       "      <td>63.66</td>\n",
       "      <td>40.59</td>\n",
       "      <td>71.79</td>\n",
       "      <td>74.24</td>\n",
       "      <td>72.30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>61.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>81.48</td>\n",
       "      <td>53.22</td>\n",
       "      <td>72.84</td>\n",
       "      <td>32.77</td>\n",
       "      <td>29.64</td>\n",
       "      <td>47.50</td>\n",
       "      <td>86.69</td>\n",
       "      <td>43.40</td>\n",
       "      <td>81.49</td>\n",
       "      <td>72.61</td>\n",
       "      <td>55.03</td>\n",
       "      <td>34.45</td>\n",
       "      <td>62.75</td>\n",
       "      <td>71.69</td>\n",
       "      <td>66.81</td>\n",
       "      <td>28.38</td>\n",
       "      <td>57.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>76.27</td>\n",
       "      <td>51.85</td>\n",
       "      <td>66.65</td>\n",
       "      <td>29.92</td>\n",
       "      <td>27.67</td>\n",
       "      <td>43.75</td>\n",
       "      <td>94.19</td>\n",
       "      <td>48.18</td>\n",
       "      <td>81.01</td>\n",
       "      <td>71.88</td>\n",
       "      <td>53.03</td>\n",
       "      <td>37.09</td>\n",
       "      <td>80.66</td>\n",
       "      <td>84.49</td>\n",
       "      <td>86.35</td>\n",
       "      <td>31.04</td>\n",
       "      <td>60.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>74.85</td>\n",
       "      <td>49.91</td>\n",
       "      <td>63.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>26.51</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.37</td>\n",
       "      <td>44.11</td>\n",
       "      <td>79.85</td>\n",
       "      <td>71.36</td>\n",
       "      <td>51.13</td>\n",
       "      <td>37.15</td>\n",
       "      <td>76.01</td>\n",
       "      <td>78.17</td>\n",
       "      <td>79.42</td>\n",
       "      <td>30.76</td>\n",
       "      <td>56.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>75.13</td>\n",
       "      <td>49.30</td>\n",
       "      <td>61.91</td>\n",
       "      <td>27.02</td>\n",
       "      <td>24.92</td>\n",
       "      <td>20.00</td>\n",
       "      <td>91.53</td>\n",
       "      <td>44.80</td>\n",
       "      <td>80.03</td>\n",
       "      <td>70.95</td>\n",
       "      <td>49.14</td>\n",
       "      <td>37.01</td>\n",
       "      <td>77.17</td>\n",
       "      <td>77.68</td>\n",
       "      <td>80.19</td>\n",
       "      <td>29.99</td>\n",
       "      <td>56.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>e5-mistral-7b-instruct</td>\n",
       "      <td>78.60</td>\n",
       "      <td>48.41</td>\n",
       "      <td>71.15</td>\n",
       "      <td>34.47</td>\n",
       "      <td>32.29</td>\n",
       "      <td>47.31</td>\n",
       "      <td>89.88</td>\n",
       "      <td>46.56</td>\n",
       "      <td>82.09</td>\n",
       "      <td>75.18</td>\n",
       "      <td>53.88</td>\n",
       "      <td>33.26</td>\n",
       "      <td>80.76</td>\n",
       "      <td>84.83</td>\n",
       "      <td>84.59</td>\n",
       "      <td>31.07</td>\n",
       "      <td>60.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>77.56</td>\n",
       "      <td>46.93</td>\n",
       "      <td>68.73</td>\n",
       "      <td>31.85</td>\n",
       "      <td>30.32</td>\n",
       "      <td>44.84</td>\n",
       "      <td>89.10</td>\n",
       "      <td>45.15</td>\n",
       "      <td>80.77</td>\n",
       "      <td>74.71</td>\n",
       "      <td>54.18</td>\n",
       "      <td>34.57</td>\n",
       "      <td>79.13</td>\n",
       "      <td>79.30</td>\n",
       "      <td>81.27</td>\n",
       "      <td>30.15</td>\n",
       "      <td>59.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>74.95</td>\n",
       "      <td>40.16</td>\n",
       "      <td>65.32</td>\n",
       "      <td>28.92</td>\n",
       "      <td>28.37</td>\n",
       "      <td>40.78</td>\n",
       "      <td>80.57</td>\n",
       "      <td>41.01</td>\n",
       "      <td>79.07</td>\n",
       "      <td>72.21</td>\n",
       "      <td>55.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>74.85</td>\n",
       "      <td>74.08</td>\n",
       "      <td>67.46</td>\n",
       "      <td>27.15</td>\n",
       "      <td>55.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>81.70</td>\n",
       "      <td>42.23</td>\n",
       "      <td>69.76</td>\n",
       "      <td>34.82</td>\n",
       "      <td>33.42</td>\n",
       "      <td>50.07</td>\n",
       "      <td>90.15</td>\n",
       "      <td>51.98</td>\n",
       "      <td>88.65</td>\n",
       "      <td>65.57</td>\n",
       "      <td>46.52</td>\n",
       "      <td>33.29</td>\n",
       "      <td>80.59</td>\n",
       "      <td>80.03</td>\n",
       "      <td>83.42</td>\n",
       "      <td>27.49</td>\n",
       "      <td>59.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>79.70</td>\n",
       "      <td>40.01</td>\n",
       "      <td>64.10</td>\n",
       "      <td>33.93</td>\n",
       "      <td>32.55</td>\n",
       "      <td>39.20</td>\n",
       "      <td>86.24</td>\n",
       "      <td>47.33</td>\n",
       "      <td>87.77</td>\n",
       "      <td>65.14</td>\n",
       "      <td>44.25</td>\n",
       "      <td>33.20</td>\n",
       "      <td>77.80</td>\n",
       "      <td>68.13</td>\n",
       "      <td>74.11</td>\n",
       "      <td>28.30</td>\n",
       "      <td>56.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>79.64</td>\n",
       "      <td>40.65</td>\n",
       "      <td>65.02</td>\n",
       "      <td>34.05</td>\n",
       "      <td>32.16</td>\n",
       "      <td>39.28</td>\n",
       "      <td>85.87</td>\n",
       "      <td>47.79</td>\n",
       "      <td>87.77</td>\n",
       "      <td>64.81</td>\n",
       "      <td>43.98</td>\n",
       "      <td>33.16</td>\n",
       "      <td>78.04</td>\n",
       "      <td>68.20</td>\n",
       "      <td>73.19</td>\n",
       "      <td>26.17</td>\n",
       "      <td>56.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gte-base-en-v1.5</td>\n",
       "      <td>86.72</td>\n",
       "      <td>46.34</td>\n",
       "      <td>77.67</td>\n",
       "      <td>37.39</td>\n",
       "      <td>32.31</td>\n",
       "      <td>48.66</td>\n",
       "      <td>95.03</td>\n",
       "      <td>52.18</td>\n",
       "      <td>85.16</td>\n",
       "      <td>76.79</td>\n",
       "      <td>63.65</td>\n",
       "      <td>35.85</td>\n",
       "      <td>79.38</td>\n",
       "      <td>85.02</td>\n",
       "      <td>86.06</td>\n",
       "      <td>31.35</td>\n",
       "      <td>63.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>84.62</td>\n",
       "      <td>44.39</td>\n",
       "      <td>71.03</td>\n",
       "      <td>35.63</td>\n",
       "      <td>30.78</td>\n",
       "      <td>26.51</td>\n",
       "      <td>90.55</td>\n",
       "      <td>47.28</td>\n",
       "      <td>83.95</td>\n",
       "      <td>75.44</td>\n",
       "      <td>61.66</td>\n",
       "      <td>35.54</td>\n",
       "      <td>75.23</td>\n",
       "      <td>78.13</td>\n",
       "      <td>79.71</td>\n",
       "      <td>29.61</td>\n",
       "      <td>59.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>85.87</td>\n",
       "      <td>46.10</td>\n",
       "      <td>74.92</td>\n",
       "      <td>36.31</td>\n",
       "      <td>32.01</td>\n",
       "      <td>44.68</td>\n",
       "      <td>94.19</td>\n",
       "      <td>50.00</td>\n",
       "      <td>84.67</td>\n",
       "      <td>73.36</td>\n",
       "      <td>62.14</td>\n",
       "      <td>35.22</td>\n",
       "      <td>77.36</td>\n",
       "      <td>81.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>31.87</td>\n",
       "      <td>62.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>instructor-base</td>\n",
       "      <td>76.92</td>\n",
       "      <td>48.48</td>\n",
       "      <td>66.00</td>\n",
       "      <td>26.40</td>\n",
       "      <td>28.38</td>\n",
       "      <td>52.77</td>\n",
       "      <td>92.06</td>\n",
       "      <td>50.66</td>\n",
       "      <td>79.36</td>\n",
       "      <td>57.88</td>\n",
       "      <td>51.18</td>\n",
       "      <td>30.76</td>\n",
       "      <td>80.02</td>\n",
       "      <td>84.78</td>\n",
       "      <td>85.85</td>\n",
       "      <td>30.57</td>\n",
       "      <td>58.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>75.07</td>\n",
       "      <td>45.79</td>\n",
       "      <td>62.38</td>\n",
       "      <td>18.05</td>\n",
       "      <td>23.13</td>\n",
       "      <td>28.64</td>\n",
       "      <td>88.39</td>\n",
       "      <td>47.66</td>\n",
       "      <td>77.92</td>\n",
       "      <td>57.70</td>\n",
       "      <td>47.45</td>\n",
       "      <td>29.77</td>\n",
       "      <td>75.48</td>\n",
       "      <td>77.97</td>\n",
       "      <td>79.99</td>\n",
       "      <td>30.37</td>\n",
       "      <td>54.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>76.37</td>\n",
       "      <td>47.66</td>\n",
       "      <td>64.62</td>\n",
       "      <td>26.05</td>\n",
       "      <td>26.55</td>\n",
       "      <td>50.55</td>\n",
       "      <td>91.30</td>\n",
       "      <td>49.67</td>\n",
       "      <td>76.63</td>\n",
       "      <td>43.47</td>\n",
       "      <td>47.03</td>\n",
       "      <td>23.11</td>\n",
       "      <td>78.86</td>\n",
       "      <td>81.96</td>\n",
       "      <td>84.21</td>\n",
       "      <td>29.17</td>\n",
       "      <td>56.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sentence-t5-base</td>\n",
       "      <td>76.60</td>\n",
       "      <td>51.34</td>\n",
       "      <td>69.70</td>\n",
       "      <td>23.11</td>\n",
       "      <td>26.03</td>\n",
       "      <td>49.27</td>\n",
       "      <td>91.23</td>\n",
       "      <td>48.46</td>\n",
       "      <td>73.96</td>\n",
       "      <td>45.76</td>\n",
       "      <td>44.84</td>\n",
       "      <td>28.64</td>\n",
       "      <td>80.18</td>\n",
       "      <td>84.03</td>\n",
       "      <td>85.52</td>\n",
       "      <td>31.39</td>\n",
       "      <td>56.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>75.73</td>\n",
       "      <td>51.30</td>\n",
       "      <td>66.57</td>\n",
       "      <td>20.04</td>\n",
       "      <td>25.06</td>\n",
       "      <td>37.17</td>\n",
       "      <td>87.86</td>\n",
       "      <td>44.85</td>\n",
       "      <td>72.05</td>\n",
       "      <td>44.58</td>\n",
       "      <td>45.41</td>\n",
       "      <td>28.48</td>\n",
       "      <td>76.72</td>\n",
       "      <td>79.69</td>\n",
       "      <td>81.32</td>\n",
       "      <td>30.32</td>\n",
       "      <td>54.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>75.20</td>\n",
       "      <td>50.20</td>\n",
       "      <td>66.83</td>\n",
       "      <td>15.02</td>\n",
       "      <td>20.41</td>\n",
       "      <td>35.38</td>\n",
       "      <td>88.39</td>\n",
       "      <td>45.16</td>\n",
       "      <td>71.17</td>\n",
       "      <td>26.76</td>\n",
       "      <td>42.14</td>\n",
       "      <td>13.65</td>\n",
       "      <td>76.32</td>\n",
       "      <td>79.26</td>\n",
       "      <td>81.24</td>\n",
       "      <td>30.84</td>\n",
       "      <td>51.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UAE-Large-V1</td>\n",
       "      <td>87.73</td>\n",
       "      <td>51.72</td>\n",
       "      <td>76.24</td>\n",
       "      <td>37.24</td>\n",
       "      <td>31.18</td>\n",
       "      <td>51.72</td>\n",
       "      <td>97.24</td>\n",
       "      <td>55.32</td>\n",
       "      <td>87.49</td>\n",
       "      <td>73.91</td>\n",
       "      <td>66.15</td>\n",
       "      <td>37.61</td>\n",
       "      <td>82.62</td>\n",
       "      <td>86.61</td>\n",
       "      <td>89.06</td>\n",
       "      <td>32.03</td>\n",
       "      <td>65.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>86.09</td>\n",
       "      <td>48.16</td>\n",
       "      <td>72.13</td>\n",
       "      <td>35.79</td>\n",
       "      <td>30.96</td>\n",
       "      <td>40.48</td>\n",
       "      <td>96.23</td>\n",
       "      <td>50.44</td>\n",
       "      <td>86.75</td>\n",
       "      <td>74.51</td>\n",
       "      <td>63.67</td>\n",
       "      <td>37.70</td>\n",
       "      <td>80.72</td>\n",
       "      <td>80.43</td>\n",
       "      <td>84.23</td>\n",
       "      <td>31.99</td>\n",
       "      <td>62.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>86.56</td>\n",
       "      <td>50.43</td>\n",
       "      <td>72.79</td>\n",
       "      <td>35.98</td>\n",
       "      <td>30.94</td>\n",
       "      <td>47.20</td>\n",
       "      <td>96.52</td>\n",
       "      <td>52.44</td>\n",
       "      <td>86.94</td>\n",
       "      <td>72.63</td>\n",
       "      <td>63.48</td>\n",
       "      <td>37.79</td>\n",
       "      <td>81.53</td>\n",
       "      <td>83.13</td>\n",
       "      <td>86.00</td>\n",
       "      <td>30.84</td>\n",
       "      <td>63.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GritLM-7B</td>\n",
       "      <td>70.44</td>\n",
       "      <td>36.03</td>\n",
       "      <td>62.90</td>\n",
       "      <td>23.67</td>\n",
       "      <td>24.13</td>\n",
       "      <td>19.57</td>\n",
       "      <td>58.58</td>\n",
       "      <td>35.56</td>\n",
       "      <td>60.05</td>\n",
       "      <td>44.57</td>\n",
       "      <td>37.33</td>\n",
       "      <td>6.99</td>\n",
       "      <td>58.07</td>\n",
       "      <td>57.60</td>\n",
       "      <td>48.32</td>\n",
       "      <td>24.11</td>\n",
       "      <td>41.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>62.05</td>\n",
       "      <td>35.13</td>\n",
       "      <td>56.75</td>\n",
       "      <td>14.75</td>\n",
       "      <td>18.80</td>\n",
       "      <td>10.94</td>\n",
       "      <td>44.45</td>\n",
       "      <td>29.86</td>\n",
       "      <td>53.90</td>\n",
       "      <td>39.52</td>\n",
       "      <td>33.61</td>\n",
       "      <td>6.25</td>\n",
       "      <td>27.69</td>\n",
       "      <td>32.07</td>\n",
       "      <td>27.29</td>\n",
       "      <td>25.80</td>\n",
       "      <td>32.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>56.42</td>\n",
       "      <td>34.91</td>\n",
       "      <td>49.36</td>\n",
       "      <td>19.41</td>\n",
       "      <td>15.82</td>\n",
       "      <td>10.04</td>\n",
       "      <td>40.73</td>\n",
       "      <td>26.18</td>\n",
       "      <td>48.93</td>\n",
       "      <td>36.41</td>\n",
       "      <td>29.73</td>\n",
       "      <td>6.19</td>\n",
       "      <td>26.64</td>\n",
       "      <td>41.04</td>\n",
       "      <td>23.69</td>\n",
       "      <td>22.81</td>\n",
       "      <td>30.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sup-simcse-bert-base-uncased</td>\n",
       "      <td>75.49</td>\n",
       "      <td>45.69</td>\n",
       "      <td>67.21</td>\n",
       "      <td>25.70</td>\n",
       "      <td>25.85</td>\n",
       "      <td>31.67</td>\n",
       "      <td>81.74</td>\n",
       "      <td>40.32</td>\n",
       "      <td>71.14</td>\n",
       "      <td>33.89</td>\n",
       "      <td>39.56</td>\n",
       "      <td>13.49</td>\n",
       "      <td>80.62</td>\n",
       "      <td>80.71</td>\n",
       "      <td>82.69</td>\n",
       "      <td>31.17</td>\n",
       "      <td>51.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>71.42</td>\n",
       "      <td>43.49</td>\n",
       "      <td>60.38</td>\n",
       "      <td>25.11</td>\n",
       "      <td>25.19</td>\n",
       "      <td>28.40</td>\n",
       "      <td>76.54</td>\n",
       "      <td>37.34</td>\n",
       "      <td>70.02</td>\n",
       "      <td>33.66</td>\n",
       "      <td>36.79</td>\n",
       "      <td>13.45</td>\n",
       "      <td>77.53</td>\n",
       "      <td>75.82</td>\n",
       "      <td>78.32</td>\n",
       "      <td>30.76</td>\n",
       "      <td>49.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>72.40</td>\n",
       "      <td>43.34</td>\n",
       "      <td>61.03</td>\n",
       "      <td>24.80</td>\n",
       "      <td>25.17</td>\n",
       "      <td>29.22</td>\n",
       "      <td>76.51</td>\n",
       "      <td>38.31</td>\n",
       "      <td>70.25</td>\n",
       "      <td>29.89</td>\n",
       "      <td>38.38</td>\n",
       "      <td>8.84</td>\n",
       "      <td>77.74</td>\n",
       "      <td>77.05</td>\n",
       "      <td>79.53</td>\n",
       "      <td>30.18</td>\n",
       "      <td>48.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  Banking77Classification  \\\n",
       "0               bge-base-en-v1.5                    83.99   \n",
       "1                w/ benign token                    82.57   \n",
       "2                 w/ sticky oken                    82.31   \n",
       "3          gte-Qwen2-7B-instruct                    84.00   \n",
       "4                w/ benign token                    82.89   \n",
       "5                 w/ sticky oken                    81.48   \n",
       "6                        e5-base                    76.27   \n",
       "7                w/ benign token                    74.85   \n",
       "8                 w/ sticky oken                    75.13   \n",
       "9         e5-mistral-7b-instruct                    78.60   \n",
       "10               w/ benign token                    77.56   \n",
       "11                w/ sticky oken                    74.95   \n",
       "12             all-mpnet-base-v2                    81.70   \n",
       "13               w/ benign token                    79.70   \n",
       "14                w/ sticky oken                    79.64   \n",
       "15              gte-base-en-v1.5                    86.72   \n",
       "16               w/ benign token                    84.62   \n",
       "17                w/ sticky oken                    85.87   \n",
       "18               instructor-base                    76.92   \n",
       "19               w/ benign token                    75.07   \n",
       "20                w/ sticky oken                    76.37   \n",
       "21              sentence-t5-base                    76.60   \n",
       "22               w/ benign token                    75.73   \n",
       "23                w/ sticky oken                    75.20   \n",
       "24                  UAE-Large-V1                    87.73   \n",
       "25               w/ benign token                    86.09   \n",
       "26                w/ sticky oken                    86.56   \n",
       "27                     GritLM-7B                    70.44   \n",
       "28               w/ benign token                    62.05   \n",
       "29                w/ sticky oken                    56.42   \n",
       "30  sup-simcse-bert-base-uncased                    75.49   \n",
       "31               w/ benign token                    71.42   \n",
       "32                w/ sticky oken                    72.40   \n",
       "\n",
       "    EmotionClassification  MassiveIntentClassification  BiorxivClusteringS2S  \\\n",
       "0                   54.61                        72.64                 36.62   \n",
       "1                   52.70                        66.98                 36.20   \n",
       "2                   51.98                        67.62                 35.93   \n",
       "3                   55.28                        77.46                 39.16   \n",
       "4                   54.43                        74.06                 38.05   \n",
       "5                   53.22                        72.84                 32.77   \n",
       "6                   51.85                        66.65                 29.92   \n",
       "7                   49.91                        63.00                 28.94   \n",
       "8                   49.30                        61.91                 27.02   \n",
       "9                   48.41                        71.15                 34.47   \n",
       "10                  46.93                        68.73                 31.85   \n",
       "11                  40.16                        65.32                 28.92   \n",
       "12                  42.23                        69.76                 34.82   \n",
       "13                  40.01                        64.10                 33.93   \n",
       "14                  40.65                        65.02                 34.05   \n",
       "15                  46.34                        77.67                 37.39   \n",
       "16                  44.39                        71.03                 35.63   \n",
       "17                  46.10                        74.92                 36.31   \n",
       "18                  48.48                        66.00                 26.40   \n",
       "19                  45.79                        62.38                 18.05   \n",
       "20                  47.66                        64.62                 26.05   \n",
       "21                  51.34                        69.70                 23.11   \n",
       "22                  51.30                        66.57                 20.04   \n",
       "23                  50.20                        66.83                 15.02   \n",
       "24                  51.72                        76.24                 37.24   \n",
       "25                  48.16                        72.13                 35.79   \n",
       "26                  50.43                        72.79                 35.98   \n",
       "27                  36.03                        62.90                 23.67   \n",
       "28                  35.13                        56.75                 14.75   \n",
       "29                  34.91                        49.36                 19.41   \n",
       "30                  45.69                        67.21                 25.70   \n",
       "31                  43.49                        60.38                 25.11   \n",
       "32                  43.34                        61.03                 24.80   \n",
       "\n",
       "    MedrxivClusteringS2S  TwentyNewsgroupsClustering  \\\n",
       "0                  31.68                       50.75   \n",
       "1                  30.74                       44.27   \n",
       "2                  31.06                       43.36   \n",
       "3                  33.34                       52.34   \n",
       "4                  32.67                       48.35   \n",
       "5                  29.64                       47.50   \n",
       "6                  27.67                       43.75   \n",
       "7                  26.51                       22.15   \n",
       "8                  24.92                       20.00   \n",
       "9                  32.29                       47.31   \n",
       "10                 30.32                       44.84   \n",
       "11                 28.37                       40.78   \n",
       "12                 33.42                       50.07   \n",
       "13                 32.55                       39.20   \n",
       "14                 32.16                       39.28   \n",
       "15                 32.31                       48.66   \n",
       "16                 30.78                       26.51   \n",
       "17                 32.01                       44.68   \n",
       "18                 28.38                       52.77   \n",
       "19                 23.13                       28.64   \n",
       "20                 26.55                       50.55   \n",
       "21                 26.03                       49.27   \n",
       "22                 25.06                       37.17   \n",
       "23                 20.41                       35.38   \n",
       "24                 31.18                       51.72   \n",
       "25                 30.96                       40.48   \n",
       "26                 30.94                       47.20   \n",
       "27                 24.13                       19.57   \n",
       "28                 18.80                       10.94   \n",
       "29                 15.82                       10.04   \n",
       "30                 25.85                       31.67   \n",
       "31                 25.19                       28.40   \n",
       "32                 25.17                       29.22   \n",
       "\n",
       "    SprintDuplicateQuestions  StackOverflowDupQuestions  SciDocsRR  SciFact  \\\n",
       "0                      96.37                      54.62      87.49    73.76   \n",
       "1                      95.18                      50.94      86.59    72.91   \n",
       "2                      94.95                      50.99      86.61    73.70   \n",
       "3                      93.13                      52.87      86.25    79.55   \n",
       "4                      93.08                      49.39      85.66    79.68   \n",
       "5                      86.69                      43.40      81.49    72.61   \n",
       "6                      94.19                      48.18      81.01    71.88   \n",
       "7                      91.37                      44.11      79.85    71.36   \n",
       "8                      91.53                      44.80      80.03    70.95   \n",
       "9                      89.88                      46.56      82.09    75.18   \n",
       "10                     89.10                      45.15      80.77    74.71   \n",
       "11                     80.57                      41.01      79.07    72.21   \n",
       "12                     90.15                      51.98      88.65    65.57   \n",
       "13                     86.24                      47.33      87.77    65.14   \n",
       "14                     85.87                      47.79      87.77    64.81   \n",
       "15                     95.03                      52.18      85.16    76.79   \n",
       "16                     90.55                      47.28      83.95    75.44   \n",
       "17                     94.19                      50.00      84.67    73.36   \n",
       "18                     92.06                      50.66      79.36    57.88   \n",
       "19                     88.39                      47.66      77.92    57.70   \n",
       "20                     91.30                      49.67      76.63    43.47   \n",
       "21                     91.23                      48.46      73.96    45.76   \n",
       "22                     87.86                      44.85      72.05    44.58   \n",
       "23                     88.39                      45.16      71.17    26.76   \n",
       "24                     97.24                      55.32      87.49    73.91   \n",
       "25                     96.23                      50.44      86.75    74.51   \n",
       "26                     96.52                      52.44      86.94    72.63   \n",
       "27                     58.58                      35.56      60.05    44.57   \n",
       "28                     44.45                      29.86      53.90    39.52   \n",
       "29                     40.73                      26.18      48.93    36.41   \n",
       "30                     81.74                      40.32      71.14    33.89   \n",
       "31                     76.54                      37.34      70.02    33.66   \n",
       "32                     76.51                      38.31      70.25    29.89   \n",
       "\n",
       "    ArguAna  NFCorpus  SICK-R  STS16  STSBenchmark  SummEval  Avarage  \n",
       "0     63.62     36.81   80.30  85.47         86.42     31.04    64.14  \n",
       "1     60.63     37.15   76.10  80.97         82.02     29.97    61.62  \n",
       "2     61.31     37.05   77.80  80.11         81.72     30.31    61.68  \n",
       "3     64.71     40.33   78.06  82.82         81.61     30.46    64.46  \n",
       "4     63.66     40.59   71.79  74.24         72.30     29.95    61.92  \n",
       "5     55.03     34.45   62.75  71.69         66.81     28.38    57.55  \n",
       "6     53.03     37.09   80.66  84.49         86.35     31.04    60.25  \n",
       "7     51.13     37.15   76.01  78.17         79.42     30.76    56.54  \n",
       "8     49.14     37.01   77.17  77.68         80.19     29.99    56.05  \n",
       "9     53.88     33.26   80.76  84.83         84.59     31.07    60.90  \n",
       "10    54.18     34.57   79.13  79.30         81.27     30.15    59.29  \n",
       "11    55.30     33.17   74.85  74.08         67.46     27.15    55.21  \n",
       "12    46.52     33.29   80.59  80.03         83.42     27.49    59.98  \n",
       "13    44.25     33.20   77.80  68.13         74.11     28.30    56.36  \n",
       "14    43.98     33.16   78.04  68.20         73.19     26.17    56.24  \n",
       "15    63.65     35.85   79.38  85.02         86.06     31.35    63.72  \n",
       "16    61.66     35.54   75.23  78.13         79.71     29.61    59.38  \n",
       "17    62.14     35.22   77.36  81.75         83.65     31.87    62.13  \n",
       "18    51.18     30.76   80.02  84.78         85.85     30.57    58.88  \n",
       "19    47.45     29.77   75.48  77.97         79.99     30.37    54.11  \n",
       "20    47.03     23.11   78.86  81.96         84.21     29.17    56.07  \n",
       "21    44.84     28.64   80.18  84.03         85.52     31.39    56.88  \n",
       "22    45.41     28.48   76.72  79.69         81.32     30.32    54.20  \n",
       "23    42.14     13.65   76.32  79.26         81.24     30.84    51.12  \n",
       "24    66.15     37.61   82.62  86.61         89.06     32.03    65.24  \n",
       "25    63.67     37.70   80.72  80.43         84.23     31.99    62.52  \n",
       "26    63.48     37.79   81.53  83.13         86.00     30.84    63.45  \n",
       "27    37.33      6.99   58.07  57.60         48.32     24.11    41.75  \n",
       "28    33.61      6.25   27.69  32.07         27.29     25.80    32.43  \n",
       "29    29.73      6.19   26.64  41.04         23.69     22.81    30.52  \n",
       "30    39.56     13.49   80.62  80.71         82.69     31.17    51.68  \n",
       "31    36.79     13.45   77.53  75.82         78.32     30.76    49.01  \n",
       "32    38.38      8.84   77.74  77.05         79.53     30.18    48.91  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd.iloc[:, 1:] = result_pd.iloc[:, 1:].applymap(lambda x: round(x * 100, 2) if pd.notnull(x) else x)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果保存为markdown格式\n",
    "result_pd.to_markdown(\"result.md\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果保存为latex格式\n",
    "result_pd.to_latex(\"downstream_result.tex\", index=False, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_excel(\"result.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stickytoken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
