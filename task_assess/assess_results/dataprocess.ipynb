{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = \"/root/StickyToken/task_assess/results/bge-base-en-v1.5_with_benign_tokens/no_model_name_available/no_revision_available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = os.listdir(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [task.removesuffix(\".json\") for task in task_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArguAna',\n",
       " 'Banking77Classification',\n",
       " 'BiorxivClusteringS2S',\n",
       " 'EmotionClassification',\n",
       " 'MassiveIntentClassification',\n",
       " 'MedrxivClusteringS2S',\n",
       " 'NFCorpus',\n",
       " 'SICK-R',\n",
       " 'STS16',\n",
       " 'STSBenchmark',\n",
       " 'SciDocsRR',\n",
       " 'SciFact',\n",
       " 'SprintDuplicateQuestions',\n",
       " 'StackOverflowDupQuestions',\n",
       " 'SummEval',\n",
       " 'TwentyNewsgroupsClustering',\n",
       " 'model_meta']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.listdir(\"./\")\n",
    "temp = [item for item in temp if os.path.isdir(item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UAE-Large-V1_with_sticky_tokens',\n",
       " 'bge-base-en-v1.5_with_benign_tokens',\n",
       " 'bge-base-en-v1.5_with_sticky_tokens',\n",
       " 'e5-base_with_sticky_tokens',\n",
       " 'gte-base-en-v1.5_with_benign_tokens',\n",
       " 'gte-base-en-v1.5_with_sticky_tokens',\n",
       " 'instructor-base_with_sticky_tokens',\n",
       " 'sentence-t5-base',\n",
       " 'sentence-t5-base_with_benign_tokens',\n",
       " 'sentence-t5-base_with_sticky_tokens',\n",
       " 'sup-simcse-bert-base-uncased_with_sticky_tokens',\n",
       " 'instructor-base_with_benign_tokens',\n",
       " 'sup-simcse-bert-base-uncased_with_benign_tokens',\n",
       " 'UAE-Large-V1_with_benign_tokens',\n",
       " 'e5-base_with_benign_tokens',\n",
       " 'bge-base-en-v1.5',\n",
       " 'gte-base-en-v1.5',\n",
       " 'instructor-base',\n",
       " 'sup-simcse-bert-base-uncased',\n",
       " 'UAE-Large-V1',\n",
       " 'e5-base',\n",
       " 'all-mpnet-base-v2',\n",
       " 'all-mpnet-base-v2_with_benign_tokens',\n",
       " 'all-mpnet-base-v2_with_sticky_tokens']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = set([model.split(\"_with_\")[0] for model in temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UAE-Large-V1',\n",
       " 'all-mpnet-base-v2',\n",
       " 'bge-base-en-v1.5',\n",
       " 'e5-base',\n",
       " 'gte-base-en-v1.5',\n",
       " 'instructor-base',\n",
       " 'sentence-t5-base',\n",
       " 'sup-simcse-bert-base-uncased'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "result_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = \"Banking77Classification\tEmotionClassification\tMassiveIntentClassification\tBiorxivClusteringS2S\tMedrxivClusteringS2S\tTwentyNewsgroupsClustering\tSprintDuplicateQuestions\tStackOverflowDupQuestions\tSciDocsRR\tSciFact\tArguAna\tNFCorpus\tSICK-R\tSTS16\tSTSBenchmark\tSummEval\".split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_list = [\"\", \"_with_benign_tokens\", \"_with_sticky_tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_set:\n",
    "    for suffix in suffix_list:\n",
    "        if suffix == \"\":\n",
    "            result_dict[\"model\"].append(model)\n",
    "        elif \"sticky\" in suffix:\n",
    "            result_dict[\"model\"].append(\"w/ sticky oken\")\n",
    "        elif \"benign\" in suffix:\n",
    "            result_dict[\"model\"].append(\"w/ benign token\")\n",
    "        else:\n",
    "            print(\"error\")\n",
    "            continue\n",
    "        for task in task_list:\n",
    "            try:\n",
    "                with open(f\"{model}{suffix}/no_model_name_available/no_revision_available/{task}.json\") as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                result_dict[task].append(data[\"scores\"][\"test\"][0][\"main_score\"])\n",
    "            except:\n",
    "                result_dict[task].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Banking77Classification</th>\n",
       "      <th>EmotionClassification</th>\n",
       "      <th>MassiveIntentClassification</th>\n",
       "      <th>BiorxivClusteringS2S</th>\n",
       "      <th>MedrxivClusteringS2S</th>\n",
       "      <th>TwentyNewsgroupsClustering</th>\n",
       "      <th>SprintDuplicateQuestions</th>\n",
       "      <th>StackOverflowDupQuestions</th>\n",
       "      <th>SciDocsRR</th>\n",
       "      <th>SciFact</th>\n",
       "      <th>ArguAna</th>\n",
       "      <th>NFCorpus</th>\n",
       "      <th>SICK-R</th>\n",
       "      <th>STS16</th>\n",
       "      <th>STSBenchmark</th>\n",
       "      <th>SummEval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-t5-base</td>\n",
       "      <td>0.766039</td>\n",
       "      <td>0.51340</td>\n",
       "      <td>0.696974</td>\n",
       "      <td>0.231079</td>\n",
       "      <td>0.260272</td>\n",
       "      <td>0.492733</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.484637</td>\n",
       "      <td>0.739623</td>\n",
       "      <td>0.45760</td>\n",
       "      <td>0.44844</td>\n",
       "      <td>0.28645</td>\n",
       "      <td>0.801823</td>\n",
       "      <td>0.840323</td>\n",
       "      <td>0.855203</td>\n",
       "      <td>0.313910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.757273</td>\n",
       "      <td>0.51305</td>\n",
       "      <td>0.665669</td>\n",
       "      <td>0.200376</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.371668</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.448502</td>\n",
       "      <td>0.720505</td>\n",
       "      <td>0.44580</td>\n",
       "      <td>0.45411</td>\n",
       "      <td>0.28485</td>\n",
       "      <td>0.767207</td>\n",
       "      <td>0.796880</td>\n",
       "      <td>0.813157</td>\n",
       "      <td>0.303225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.752013</td>\n",
       "      <td>0.50195</td>\n",
       "      <td>0.668325</td>\n",
       "      <td>0.150215</td>\n",
       "      <td>0.204122</td>\n",
       "      <td>0.353841</td>\n",
       "      <td>0.883928</td>\n",
       "      <td>0.451617</td>\n",
       "      <td>0.711696</td>\n",
       "      <td>0.26757</td>\n",
       "      <td>0.42141</td>\n",
       "      <td>0.13650</td>\n",
       "      <td>0.763194</td>\n",
       "      <td>0.792624</td>\n",
       "      <td>0.812406</td>\n",
       "      <td>0.308402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UAE-Large-V1</td>\n",
       "      <td>0.877305</td>\n",
       "      <td>0.51720</td>\n",
       "      <td>0.762408</td>\n",
       "      <td>0.372365</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.517155</td>\n",
       "      <td>0.972370</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.874908</td>\n",
       "      <td>0.73909</td>\n",
       "      <td>0.66150</td>\n",
       "      <td>0.37609</td>\n",
       "      <td>0.826233</td>\n",
       "      <td>0.866117</td>\n",
       "      <td>0.890608</td>\n",
       "      <td>0.320291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.860909</td>\n",
       "      <td>0.48165</td>\n",
       "      <td>0.721318</td>\n",
       "      <td>0.357911</td>\n",
       "      <td>0.309552</td>\n",
       "      <td>0.404801</td>\n",
       "      <td>0.962295</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>0.867492</td>\n",
       "      <td>0.74513</td>\n",
       "      <td>0.63666</td>\n",
       "      <td>0.37703</td>\n",
       "      <td>0.807150</td>\n",
       "      <td>0.804317</td>\n",
       "      <td>0.842266</td>\n",
       "      <td>0.319858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.865584</td>\n",
       "      <td>0.50430</td>\n",
       "      <td>0.727875</td>\n",
       "      <td>0.359789</td>\n",
       "      <td>0.309371</td>\n",
       "      <td>0.471986</td>\n",
       "      <td>0.965171</td>\n",
       "      <td>0.524402</td>\n",
       "      <td>0.869359</td>\n",
       "      <td>0.72634</td>\n",
       "      <td>0.63482</td>\n",
       "      <td>0.37791</td>\n",
       "      <td>0.815291</td>\n",
       "      <td>0.831341</td>\n",
       "      <td>0.859991</td>\n",
       "      <td>0.308443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>0.762662</td>\n",
       "      <td>0.51850</td>\n",
       "      <td>0.666543</td>\n",
       "      <td>0.299163</td>\n",
       "      <td>0.276719</td>\n",
       "      <td>0.437485</td>\n",
       "      <td>0.941856</td>\n",
       "      <td>0.481834</td>\n",
       "      <td>0.810134</td>\n",
       "      <td>0.71880</td>\n",
       "      <td>0.53033</td>\n",
       "      <td>0.37087</td>\n",
       "      <td>0.806585</td>\n",
       "      <td>0.844863</td>\n",
       "      <td>0.863475</td>\n",
       "      <td>0.310448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.748539</td>\n",
       "      <td>0.49910</td>\n",
       "      <td>0.630027</td>\n",
       "      <td>0.289443</td>\n",
       "      <td>0.265082</td>\n",
       "      <td>0.221486</td>\n",
       "      <td>0.913664</td>\n",
       "      <td>0.441079</td>\n",
       "      <td>0.798544</td>\n",
       "      <td>0.71355</td>\n",
       "      <td>0.51130</td>\n",
       "      <td>0.37150</td>\n",
       "      <td>0.760070</td>\n",
       "      <td>0.781713</td>\n",
       "      <td>0.794241</td>\n",
       "      <td>0.307588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.751266</td>\n",
       "      <td>0.49305</td>\n",
       "      <td>0.619132</td>\n",
       "      <td>0.270223</td>\n",
       "      <td>0.249217</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>0.915302</td>\n",
       "      <td>0.448004</td>\n",
       "      <td>0.800319</td>\n",
       "      <td>0.70948</td>\n",
       "      <td>0.49142</td>\n",
       "      <td>0.37011</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>0.776764</td>\n",
       "      <td>0.801895</td>\n",
       "      <td>0.299889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gte-base-en-v1.5</td>\n",
       "      <td>0.867175</td>\n",
       "      <td>0.46335</td>\n",
       "      <td>0.776664</td>\n",
       "      <td>0.373946</td>\n",
       "      <td>0.323055</td>\n",
       "      <td>0.486565</td>\n",
       "      <td>0.950349</td>\n",
       "      <td>0.521759</td>\n",
       "      <td>0.851639</td>\n",
       "      <td>0.76792</td>\n",
       "      <td>0.63648</td>\n",
       "      <td>0.35848</td>\n",
       "      <td>0.793815</td>\n",
       "      <td>0.850244</td>\n",
       "      <td>0.860643</td>\n",
       "      <td>0.313472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.844351</td>\n",
       "      <td>0.44260</td>\n",
       "      <td>0.703598</td>\n",
       "      <td>0.361083</td>\n",
       "      <td>0.310269</td>\n",
       "      <td>0.202049</td>\n",
       "      <td>0.899652</td>\n",
       "      <td>0.461640</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>0.75415</td>\n",
       "      <td>0.61584</td>\n",
       "      <td>0.35766</td>\n",
       "      <td>0.748503</td>\n",
       "      <td>0.769580</td>\n",
       "      <td>0.784894</td>\n",
       "      <td>0.304555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.858701</td>\n",
       "      <td>0.46100</td>\n",
       "      <td>0.749159</td>\n",
       "      <td>0.363070</td>\n",
       "      <td>0.320069</td>\n",
       "      <td>0.446836</td>\n",
       "      <td>0.941943</td>\n",
       "      <td>0.499956</td>\n",
       "      <td>0.846739</td>\n",
       "      <td>0.73364</td>\n",
       "      <td>0.62139</td>\n",
       "      <td>0.35217</td>\n",
       "      <td>0.773593</td>\n",
       "      <td>0.817487</td>\n",
       "      <td>0.836534</td>\n",
       "      <td>0.318684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sup-simcse-bert-base-uncased</td>\n",
       "      <td>0.754870</td>\n",
       "      <td>0.45690</td>\n",
       "      <td>0.672058</td>\n",
       "      <td>0.257039</td>\n",
       "      <td>0.258510</td>\n",
       "      <td>0.316721</td>\n",
       "      <td>0.817385</td>\n",
       "      <td>0.403188</td>\n",
       "      <td>0.711449</td>\n",
       "      <td>0.33889</td>\n",
       "      <td>0.39556</td>\n",
       "      <td>0.13487</td>\n",
       "      <td>0.806244</td>\n",
       "      <td>0.807146</td>\n",
       "      <td>0.826862</td>\n",
       "      <td>0.311741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.714221</td>\n",
       "      <td>0.43490</td>\n",
       "      <td>0.603833</td>\n",
       "      <td>0.251126</td>\n",
       "      <td>0.251914</td>\n",
       "      <td>0.284020</td>\n",
       "      <td>0.765369</td>\n",
       "      <td>0.373431</td>\n",
       "      <td>0.700181</td>\n",
       "      <td>0.33656</td>\n",
       "      <td>0.36787</td>\n",
       "      <td>0.13446</td>\n",
       "      <td>0.775304</td>\n",
       "      <td>0.758212</td>\n",
       "      <td>0.783215</td>\n",
       "      <td>0.307569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.43345</td>\n",
       "      <td>0.610256</td>\n",
       "      <td>0.247981</td>\n",
       "      <td>0.251733</td>\n",
       "      <td>0.292178</td>\n",
       "      <td>0.765093</td>\n",
       "      <td>0.383072</td>\n",
       "      <td>0.702481</td>\n",
       "      <td>0.29886</td>\n",
       "      <td>0.38384</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.777372</td>\n",
       "      <td>0.770455</td>\n",
       "      <td>0.795337</td>\n",
       "      <td>0.301765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>0.817013</td>\n",
       "      <td>0.42225</td>\n",
       "      <td>0.697579</td>\n",
       "      <td>0.348199</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>0.500655</td>\n",
       "      <td>0.901455</td>\n",
       "      <td>0.519791</td>\n",
       "      <td>0.886540</td>\n",
       "      <td>0.65570</td>\n",
       "      <td>0.46521</td>\n",
       "      <td>0.33289</td>\n",
       "      <td>0.805854</td>\n",
       "      <td>0.800301</td>\n",
       "      <td>0.834219</td>\n",
       "      <td>0.274859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.797013</td>\n",
       "      <td>0.40010</td>\n",
       "      <td>0.640989</td>\n",
       "      <td>0.339270</td>\n",
       "      <td>0.325532</td>\n",
       "      <td>0.392039</td>\n",
       "      <td>0.862363</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>0.877669</td>\n",
       "      <td>0.65138</td>\n",
       "      <td>0.44247</td>\n",
       "      <td>0.33196</td>\n",
       "      <td>0.777985</td>\n",
       "      <td>0.681311</td>\n",
       "      <td>0.741146</td>\n",
       "      <td>0.282988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.796396</td>\n",
       "      <td>0.40650</td>\n",
       "      <td>0.650168</td>\n",
       "      <td>0.340461</td>\n",
       "      <td>0.321565</td>\n",
       "      <td>0.392844</td>\n",
       "      <td>0.858719</td>\n",
       "      <td>0.477901</td>\n",
       "      <td>0.877694</td>\n",
       "      <td>0.64806</td>\n",
       "      <td>0.43979</td>\n",
       "      <td>0.33158</td>\n",
       "      <td>0.780371</td>\n",
       "      <td>0.681960</td>\n",
       "      <td>0.731903</td>\n",
       "      <td>0.261737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>instructor-base</td>\n",
       "      <td>0.769156</td>\n",
       "      <td>0.48480</td>\n",
       "      <td>0.659953</td>\n",
       "      <td>0.264031</td>\n",
       "      <td>0.283780</td>\n",
       "      <td>0.527689</td>\n",
       "      <td>0.920578</td>\n",
       "      <td>0.506645</td>\n",
       "      <td>0.793603</td>\n",
       "      <td>0.57883</td>\n",
       "      <td>0.51176</td>\n",
       "      <td>0.30757</td>\n",
       "      <td>0.800247</td>\n",
       "      <td>0.847774</td>\n",
       "      <td>0.858482</td>\n",
       "      <td>0.305743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.750714</td>\n",
       "      <td>0.45790</td>\n",
       "      <td>0.623806</td>\n",
       "      <td>0.180528</td>\n",
       "      <td>0.231340</td>\n",
       "      <td>0.286438</td>\n",
       "      <td>0.883939</td>\n",
       "      <td>0.476635</td>\n",
       "      <td>0.779199</td>\n",
       "      <td>0.57702</td>\n",
       "      <td>0.47446</td>\n",
       "      <td>0.29770</td>\n",
       "      <td>0.754825</td>\n",
       "      <td>0.779680</td>\n",
       "      <td>0.799894</td>\n",
       "      <td>0.303668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.763734</td>\n",
       "      <td>0.47665</td>\n",
       "      <td>0.646167</td>\n",
       "      <td>0.260460</td>\n",
       "      <td>0.265516</td>\n",
       "      <td>0.505472</td>\n",
       "      <td>0.912965</td>\n",
       "      <td>0.496660</td>\n",
       "      <td>0.766260</td>\n",
       "      <td>0.43471</td>\n",
       "      <td>0.47030</td>\n",
       "      <td>0.23106</td>\n",
       "      <td>0.788639</td>\n",
       "      <td>0.819561</td>\n",
       "      <td>0.842066</td>\n",
       "      <td>0.291665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>0.839903</td>\n",
       "      <td>0.54605</td>\n",
       "      <td>0.726362</td>\n",
       "      <td>0.366180</td>\n",
       "      <td>0.316789</td>\n",
       "      <td>0.507540</td>\n",
       "      <td>0.963707</td>\n",
       "      <td>0.546166</td>\n",
       "      <td>0.874941</td>\n",
       "      <td>0.73763</td>\n",
       "      <td>0.63616</td>\n",
       "      <td>0.36810</td>\n",
       "      <td>0.803011</td>\n",
       "      <td>0.854741</td>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.310384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>0.825747</td>\n",
       "      <td>0.52700</td>\n",
       "      <td>0.669839</td>\n",
       "      <td>0.362037</td>\n",
       "      <td>0.307375</td>\n",
       "      <td>0.442676</td>\n",
       "      <td>0.951759</td>\n",
       "      <td>0.509383</td>\n",
       "      <td>0.865869</td>\n",
       "      <td>0.72909</td>\n",
       "      <td>0.60633</td>\n",
       "      <td>0.37154</td>\n",
       "      <td>0.761022</td>\n",
       "      <td>0.809686</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.299657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>0.823084</td>\n",
       "      <td>0.51980</td>\n",
       "      <td>0.676194</td>\n",
       "      <td>0.359285</td>\n",
       "      <td>0.310602</td>\n",
       "      <td>0.433612</td>\n",
       "      <td>0.949535</td>\n",
       "      <td>0.509884</td>\n",
       "      <td>0.866086</td>\n",
       "      <td>0.73702</td>\n",
       "      <td>0.61314</td>\n",
       "      <td>0.37055</td>\n",
       "      <td>0.778028</td>\n",
       "      <td>0.801143</td>\n",
       "      <td>0.817223</td>\n",
       "      <td>0.303052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  Banking77Classification  \\\n",
       "0               sentence-t5-base                 0.766039   \n",
       "1                w/ benign token                 0.757273   \n",
       "2                 w/ sticky oken                 0.752013   \n",
       "3                   UAE-Large-V1                 0.877305   \n",
       "4                w/ benign token                 0.860909   \n",
       "5                 w/ sticky oken                 0.865584   \n",
       "6                        e5-base                 0.762662   \n",
       "7                w/ benign token                 0.748539   \n",
       "8                 w/ sticky oken                 0.751266   \n",
       "9               gte-base-en-v1.5                 0.867175   \n",
       "10               w/ benign token                 0.844351   \n",
       "11                w/ sticky oken                 0.858701   \n",
       "12  sup-simcse-bert-base-uncased                 0.754870   \n",
       "13               w/ benign token                 0.714221   \n",
       "14                w/ sticky oken                 0.724026   \n",
       "15             all-mpnet-base-v2                 0.817013   \n",
       "16               w/ benign token                 0.797013   \n",
       "17                w/ sticky oken                 0.796396   \n",
       "18               instructor-base                 0.769156   \n",
       "19               w/ benign token                 0.750714   \n",
       "20                w/ sticky oken                 0.763734   \n",
       "21              bge-base-en-v1.5                 0.839903   \n",
       "22               w/ benign token                 0.825747   \n",
       "23                w/ sticky oken                 0.823084   \n",
       "\n",
       "    EmotionClassification  MassiveIntentClassification  BiorxivClusteringS2S  \\\n",
       "0                 0.51340                     0.696974              0.231079   \n",
       "1                 0.51305                     0.665669              0.200376   \n",
       "2                 0.50195                     0.668325              0.150215   \n",
       "3                 0.51720                     0.762408              0.372365   \n",
       "4                 0.48165                     0.721318              0.357911   \n",
       "5                 0.50430                     0.727875              0.359789   \n",
       "6                 0.51850                     0.666543              0.299163   \n",
       "7                 0.49910                     0.630027              0.289443   \n",
       "8                 0.49305                     0.619132              0.270223   \n",
       "9                 0.46335                     0.776664              0.373946   \n",
       "10                0.44260                     0.703598              0.361083   \n",
       "11                0.46100                     0.749159              0.363070   \n",
       "12                0.45690                     0.672058              0.257039   \n",
       "13                0.43490                     0.603833              0.251126   \n",
       "14                0.43345                     0.610256              0.247981   \n",
       "15                0.42225                     0.697579              0.348199   \n",
       "16                0.40010                     0.640989              0.339270   \n",
       "17                0.40650                     0.650168              0.340461   \n",
       "18                0.48480                     0.659953              0.264031   \n",
       "19                0.45790                     0.623806              0.180528   \n",
       "20                0.47665                     0.646167              0.260460   \n",
       "21                0.54605                     0.726362              0.366180   \n",
       "22                0.52700                     0.669839              0.362037   \n",
       "23                0.51980                     0.676194              0.359285   \n",
       "\n",
       "    MedrxivClusteringS2S  TwentyNewsgroupsClustering  \\\n",
       "0               0.260272                    0.492733   \n",
       "1               0.250571                    0.371668   \n",
       "2               0.204122                    0.353841   \n",
       "3               0.311805                    0.517155   \n",
       "4               0.309552                    0.404801   \n",
       "5               0.309371                    0.471986   \n",
       "6               0.276719                    0.437485   \n",
       "7               0.265082                    0.221486   \n",
       "8               0.249217                    0.200038   \n",
       "9               0.323055                    0.486565   \n",
       "10              0.310269                    0.202049   \n",
       "11              0.320069                    0.446836   \n",
       "12              0.258510                    0.316721   \n",
       "13              0.251914                    0.284020   \n",
       "14              0.251733                    0.292178   \n",
       "15              0.334190                    0.500655   \n",
       "16              0.325532                    0.392039   \n",
       "17              0.321565                    0.392844   \n",
       "18              0.283780                    0.527689   \n",
       "19              0.231340                    0.286438   \n",
       "20              0.265516                    0.505472   \n",
       "21              0.316789                    0.507540   \n",
       "22              0.307375                    0.442676   \n",
       "23              0.310602                    0.433612   \n",
       "\n",
       "    SprintDuplicateQuestions  StackOverflowDupQuestions  SciDocsRR  SciFact  \\\n",
       "0                   0.912281                   0.484637   0.739623  0.45760   \n",
       "1                   0.878646                   0.448502   0.720505  0.44580   \n",
       "2                   0.883928                   0.451617   0.711696  0.26757   \n",
       "3                   0.972370                   0.553200   0.874908  0.73909   \n",
       "4                   0.962295                   0.504425   0.867492  0.74513   \n",
       "5                   0.965171                   0.524402   0.869359  0.72634   \n",
       "6                   0.941856                   0.481834   0.810134  0.71880   \n",
       "7                   0.913664                   0.441079   0.798544  0.71355   \n",
       "8                   0.915302                   0.448004   0.800319  0.70948   \n",
       "9                   0.950349                   0.521759   0.851639  0.76792   \n",
       "10                  0.899652                   0.461640   0.837690  0.75415   \n",
       "11                  0.941943                   0.499956   0.846739  0.73364   \n",
       "12                  0.817385                   0.403188   0.711449  0.33889   \n",
       "13                  0.765369                   0.373431   0.700181  0.33656   \n",
       "14                  0.765093                   0.383072   0.702481  0.29886   \n",
       "15                  0.901455                   0.519791   0.886540  0.65570   \n",
       "16                  0.862363                   0.473333   0.877669  0.65138   \n",
       "17                  0.858719                   0.477901   0.877694  0.64806   \n",
       "18                  0.920578                   0.506645   0.793603  0.57883   \n",
       "19                  0.883939                   0.476635   0.779199  0.57702   \n",
       "20                  0.912965                   0.496660   0.766260  0.43471   \n",
       "21                  0.963707                   0.546166   0.874941  0.73763   \n",
       "22                  0.951759                   0.509383   0.865869  0.72909   \n",
       "23                  0.949535                   0.509884   0.866086  0.73702   \n",
       "\n",
       "    ArguAna  NFCorpus    SICK-R     STS16  STSBenchmark  SummEval  \n",
       "0   0.44844   0.28645  0.801823  0.840323      0.855203  0.313910  \n",
       "1   0.45411   0.28485  0.767207  0.796880      0.813157  0.303225  \n",
       "2   0.42141   0.13650  0.763194  0.792624      0.812406  0.308402  \n",
       "3   0.66150   0.37609  0.826233  0.866117      0.890608  0.320291  \n",
       "4   0.63666   0.37703  0.807150  0.804317      0.842266  0.319858  \n",
       "5   0.63482   0.37791  0.815291  0.831341      0.859991  0.308443  \n",
       "6   0.53033   0.37087  0.806585  0.844863      0.863475  0.310448  \n",
       "7   0.51130   0.37150  0.760070  0.781713      0.794241  0.307588  \n",
       "8   0.49142   0.37011  0.771711  0.776764      0.801895  0.299889  \n",
       "9   0.63648   0.35848  0.793815  0.850244      0.860643  0.313472  \n",
       "10  0.61584   0.35766  0.748503  0.769580      0.784894  0.304555  \n",
       "11  0.62139   0.35217  0.773593  0.817487      0.836534  0.318684  \n",
       "12  0.39556   0.13487  0.806244  0.807146      0.826862  0.311741  \n",
       "13  0.36787   0.13446  0.775304  0.758212      0.783215  0.307569  \n",
       "14  0.38384   0.08837  0.777372  0.770455      0.795337  0.301765  \n",
       "15  0.46521   0.33289  0.805854  0.800301      0.834219  0.274859  \n",
       "16  0.44247   0.33196  0.777985  0.681311      0.741146  0.282988  \n",
       "17  0.43979   0.33158  0.780371  0.681960      0.731903  0.261737  \n",
       "18  0.51176   0.30757  0.800247  0.847774      0.858482  0.305743  \n",
       "19  0.47446   0.29770  0.754825  0.779680      0.799894  0.303668  \n",
       "20  0.47030   0.23106  0.788639  0.819561      0.842066  0.291665  \n",
       "21  0.63616   0.36810  0.803011  0.854741      0.864180  0.310384  \n",
       "22  0.60633   0.37154  0.761022  0.809686      0.820162  0.299657  \n",
       "23  0.61314   0.37055  0.778028  0.801143      0.817223  0.303052  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd = pd.DataFrame(result_dict)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_413839/2289510975.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  result_pd.iloc[:, 1:] = result_pd.iloc[:, 1:].applymap(lambda x: round(x * 100, 2) if pd.notnull(x) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Banking77Classification</th>\n",
       "      <th>EmotionClassification</th>\n",
       "      <th>MassiveIntentClassification</th>\n",
       "      <th>BiorxivClusteringS2S</th>\n",
       "      <th>MedrxivClusteringS2S</th>\n",
       "      <th>TwentyNewsgroupsClustering</th>\n",
       "      <th>SprintDuplicateQuestions</th>\n",
       "      <th>StackOverflowDupQuestions</th>\n",
       "      <th>SciDocsRR</th>\n",
       "      <th>SciFact</th>\n",
       "      <th>ArguAna</th>\n",
       "      <th>NFCorpus</th>\n",
       "      <th>SICK-R</th>\n",
       "      <th>STS16</th>\n",
       "      <th>STSBenchmark</th>\n",
       "      <th>SummEval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-t5-base</td>\n",
       "      <td>76.60</td>\n",
       "      <td>51.34</td>\n",
       "      <td>69.70</td>\n",
       "      <td>23.11</td>\n",
       "      <td>26.03</td>\n",
       "      <td>49.27</td>\n",
       "      <td>91.23</td>\n",
       "      <td>48.46</td>\n",
       "      <td>73.96</td>\n",
       "      <td>45.76</td>\n",
       "      <td>44.84</td>\n",
       "      <td>28.64</td>\n",
       "      <td>80.18</td>\n",
       "      <td>84.03</td>\n",
       "      <td>85.52</td>\n",
       "      <td>31.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>75.73</td>\n",
       "      <td>51.30</td>\n",
       "      <td>66.57</td>\n",
       "      <td>20.04</td>\n",
       "      <td>25.06</td>\n",
       "      <td>37.17</td>\n",
       "      <td>87.86</td>\n",
       "      <td>44.85</td>\n",
       "      <td>72.05</td>\n",
       "      <td>44.58</td>\n",
       "      <td>45.41</td>\n",
       "      <td>28.48</td>\n",
       "      <td>76.72</td>\n",
       "      <td>79.69</td>\n",
       "      <td>81.32</td>\n",
       "      <td>30.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>75.20</td>\n",
       "      <td>50.20</td>\n",
       "      <td>66.83</td>\n",
       "      <td>15.02</td>\n",
       "      <td>20.41</td>\n",
       "      <td>35.38</td>\n",
       "      <td>88.39</td>\n",
       "      <td>45.16</td>\n",
       "      <td>71.17</td>\n",
       "      <td>26.76</td>\n",
       "      <td>42.14</td>\n",
       "      <td>13.65</td>\n",
       "      <td>76.32</td>\n",
       "      <td>79.26</td>\n",
       "      <td>81.24</td>\n",
       "      <td>30.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UAE-Large-V1</td>\n",
       "      <td>87.73</td>\n",
       "      <td>51.72</td>\n",
       "      <td>76.24</td>\n",
       "      <td>37.24</td>\n",
       "      <td>31.18</td>\n",
       "      <td>51.72</td>\n",
       "      <td>97.24</td>\n",
       "      <td>55.32</td>\n",
       "      <td>87.49</td>\n",
       "      <td>73.91</td>\n",
       "      <td>66.15</td>\n",
       "      <td>37.61</td>\n",
       "      <td>82.62</td>\n",
       "      <td>86.61</td>\n",
       "      <td>89.06</td>\n",
       "      <td>32.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>86.09</td>\n",
       "      <td>48.16</td>\n",
       "      <td>72.13</td>\n",
       "      <td>35.79</td>\n",
       "      <td>30.96</td>\n",
       "      <td>40.48</td>\n",
       "      <td>96.23</td>\n",
       "      <td>50.44</td>\n",
       "      <td>86.75</td>\n",
       "      <td>74.51</td>\n",
       "      <td>63.67</td>\n",
       "      <td>37.70</td>\n",
       "      <td>80.72</td>\n",
       "      <td>80.43</td>\n",
       "      <td>84.23</td>\n",
       "      <td>31.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>86.56</td>\n",
       "      <td>50.43</td>\n",
       "      <td>72.79</td>\n",
       "      <td>35.98</td>\n",
       "      <td>30.94</td>\n",
       "      <td>47.20</td>\n",
       "      <td>96.52</td>\n",
       "      <td>52.44</td>\n",
       "      <td>86.94</td>\n",
       "      <td>72.63</td>\n",
       "      <td>63.48</td>\n",
       "      <td>37.79</td>\n",
       "      <td>81.53</td>\n",
       "      <td>83.13</td>\n",
       "      <td>86.00</td>\n",
       "      <td>30.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e5-base</td>\n",
       "      <td>76.27</td>\n",
       "      <td>51.85</td>\n",
       "      <td>66.65</td>\n",
       "      <td>29.92</td>\n",
       "      <td>27.67</td>\n",
       "      <td>43.75</td>\n",
       "      <td>94.19</td>\n",
       "      <td>48.18</td>\n",
       "      <td>81.01</td>\n",
       "      <td>71.88</td>\n",
       "      <td>53.03</td>\n",
       "      <td>37.09</td>\n",
       "      <td>80.66</td>\n",
       "      <td>84.49</td>\n",
       "      <td>86.35</td>\n",
       "      <td>31.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>74.85</td>\n",
       "      <td>49.91</td>\n",
       "      <td>63.00</td>\n",
       "      <td>28.94</td>\n",
       "      <td>26.51</td>\n",
       "      <td>22.15</td>\n",
       "      <td>91.37</td>\n",
       "      <td>44.11</td>\n",
       "      <td>79.85</td>\n",
       "      <td>71.36</td>\n",
       "      <td>51.13</td>\n",
       "      <td>37.15</td>\n",
       "      <td>76.01</td>\n",
       "      <td>78.17</td>\n",
       "      <td>79.42</td>\n",
       "      <td>30.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>75.13</td>\n",
       "      <td>49.30</td>\n",
       "      <td>61.91</td>\n",
       "      <td>27.02</td>\n",
       "      <td>24.92</td>\n",
       "      <td>20.00</td>\n",
       "      <td>91.53</td>\n",
       "      <td>44.80</td>\n",
       "      <td>80.03</td>\n",
       "      <td>70.95</td>\n",
       "      <td>49.14</td>\n",
       "      <td>37.01</td>\n",
       "      <td>77.17</td>\n",
       "      <td>77.68</td>\n",
       "      <td>80.19</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gte-base-en-v1.5</td>\n",
       "      <td>86.72</td>\n",
       "      <td>46.34</td>\n",
       "      <td>77.67</td>\n",
       "      <td>37.39</td>\n",
       "      <td>32.31</td>\n",
       "      <td>48.66</td>\n",
       "      <td>95.03</td>\n",
       "      <td>52.18</td>\n",
       "      <td>85.16</td>\n",
       "      <td>76.79</td>\n",
       "      <td>63.65</td>\n",
       "      <td>35.85</td>\n",
       "      <td>79.38</td>\n",
       "      <td>85.02</td>\n",
       "      <td>86.06</td>\n",
       "      <td>31.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>84.44</td>\n",
       "      <td>44.26</td>\n",
       "      <td>70.36</td>\n",
       "      <td>36.11</td>\n",
       "      <td>31.03</td>\n",
       "      <td>20.20</td>\n",
       "      <td>89.97</td>\n",
       "      <td>46.16</td>\n",
       "      <td>83.77</td>\n",
       "      <td>75.41</td>\n",
       "      <td>61.58</td>\n",
       "      <td>35.77</td>\n",
       "      <td>74.85</td>\n",
       "      <td>76.96</td>\n",
       "      <td>78.49</td>\n",
       "      <td>30.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>85.87</td>\n",
       "      <td>46.10</td>\n",
       "      <td>74.92</td>\n",
       "      <td>36.31</td>\n",
       "      <td>32.01</td>\n",
       "      <td>44.68</td>\n",
       "      <td>94.19</td>\n",
       "      <td>50.00</td>\n",
       "      <td>84.67</td>\n",
       "      <td>73.36</td>\n",
       "      <td>62.14</td>\n",
       "      <td>35.22</td>\n",
       "      <td>77.36</td>\n",
       "      <td>81.75</td>\n",
       "      <td>83.65</td>\n",
       "      <td>31.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sup-simcse-bert-base-uncased</td>\n",
       "      <td>75.49</td>\n",
       "      <td>45.69</td>\n",
       "      <td>67.21</td>\n",
       "      <td>25.70</td>\n",
       "      <td>25.85</td>\n",
       "      <td>31.67</td>\n",
       "      <td>81.74</td>\n",
       "      <td>40.32</td>\n",
       "      <td>71.14</td>\n",
       "      <td>33.89</td>\n",
       "      <td>39.56</td>\n",
       "      <td>13.49</td>\n",
       "      <td>80.62</td>\n",
       "      <td>80.71</td>\n",
       "      <td>82.69</td>\n",
       "      <td>31.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>71.42</td>\n",
       "      <td>43.49</td>\n",
       "      <td>60.38</td>\n",
       "      <td>25.11</td>\n",
       "      <td>25.19</td>\n",
       "      <td>28.40</td>\n",
       "      <td>76.54</td>\n",
       "      <td>37.34</td>\n",
       "      <td>70.02</td>\n",
       "      <td>33.66</td>\n",
       "      <td>36.79</td>\n",
       "      <td>13.45</td>\n",
       "      <td>77.53</td>\n",
       "      <td>75.82</td>\n",
       "      <td>78.32</td>\n",
       "      <td>30.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>72.40</td>\n",
       "      <td>43.34</td>\n",
       "      <td>61.03</td>\n",
       "      <td>24.80</td>\n",
       "      <td>25.17</td>\n",
       "      <td>29.22</td>\n",
       "      <td>76.51</td>\n",
       "      <td>38.31</td>\n",
       "      <td>70.25</td>\n",
       "      <td>29.89</td>\n",
       "      <td>38.38</td>\n",
       "      <td>8.84</td>\n",
       "      <td>77.74</td>\n",
       "      <td>77.05</td>\n",
       "      <td>79.53</td>\n",
       "      <td>30.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>all-mpnet-base-v2</td>\n",
       "      <td>81.70</td>\n",
       "      <td>42.23</td>\n",
       "      <td>69.76</td>\n",
       "      <td>34.82</td>\n",
       "      <td>33.42</td>\n",
       "      <td>50.07</td>\n",
       "      <td>90.15</td>\n",
       "      <td>51.98</td>\n",
       "      <td>88.65</td>\n",
       "      <td>65.57</td>\n",
       "      <td>46.52</td>\n",
       "      <td>33.29</td>\n",
       "      <td>80.59</td>\n",
       "      <td>80.03</td>\n",
       "      <td>83.42</td>\n",
       "      <td>27.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>79.70</td>\n",
       "      <td>40.01</td>\n",
       "      <td>64.10</td>\n",
       "      <td>33.93</td>\n",
       "      <td>32.55</td>\n",
       "      <td>39.20</td>\n",
       "      <td>86.24</td>\n",
       "      <td>47.33</td>\n",
       "      <td>87.77</td>\n",
       "      <td>65.14</td>\n",
       "      <td>44.25</td>\n",
       "      <td>33.20</td>\n",
       "      <td>77.80</td>\n",
       "      <td>68.13</td>\n",
       "      <td>74.11</td>\n",
       "      <td>28.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>79.64</td>\n",
       "      <td>40.65</td>\n",
       "      <td>65.02</td>\n",
       "      <td>34.05</td>\n",
       "      <td>32.16</td>\n",
       "      <td>39.28</td>\n",
       "      <td>85.87</td>\n",
       "      <td>47.79</td>\n",
       "      <td>87.77</td>\n",
       "      <td>64.81</td>\n",
       "      <td>43.98</td>\n",
       "      <td>33.16</td>\n",
       "      <td>78.04</td>\n",
       "      <td>68.20</td>\n",
       "      <td>73.19</td>\n",
       "      <td>26.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>instructor-base</td>\n",
       "      <td>76.92</td>\n",
       "      <td>48.48</td>\n",
       "      <td>66.00</td>\n",
       "      <td>26.40</td>\n",
       "      <td>28.38</td>\n",
       "      <td>52.77</td>\n",
       "      <td>92.06</td>\n",
       "      <td>50.66</td>\n",
       "      <td>79.36</td>\n",
       "      <td>57.88</td>\n",
       "      <td>51.18</td>\n",
       "      <td>30.76</td>\n",
       "      <td>80.02</td>\n",
       "      <td>84.78</td>\n",
       "      <td>85.85</td>\n",
       "      <td>30.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>75.07</td>\n",
       "      <td>45.79</td>\n",
       "      <td>62.38</td>\n",
       "      <td>18.05</td>\n",
       "      <td>23.13</td>\n",
       "      <td>28.64</td>\n",
       "      <td>88.39</td>\n",
       "      <td>47.66</td>\n",
       "      <td>77.92</td>\n",
       "      <td>57.70</td>\n",
       "      <td>47.45</td>\n",
       "      <td>29.77</td>\n",
       "      <td>75.48</td>\n",
       "      <td>77.97</td>\n",
       "      <td>79.99</td>\n",
       "      <td>30.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>76.37</td>\n",
       "      <td>47.66</td>\n",
       "      <td>64.62</td>\n",
       "      <td>26.05</td>\n",
       "      <td>26.55</td>\n",
       "      <td>50.55</td>\n",
       "      <td>91.30</td>\n",
       "      <td>49.67</td>\n",
       "      <td>76.63</td>\n",
       "      <td>43.47</td>\n",
       "      <td>47.03</td>\n",
       "      <td>23.11</td>\n",
       "      <td>78.86</td>\n",
       "      <td>81.96</td>\n",
       "      <td>84.21</td>\n",
       "      <td>29.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bge-base-en-v1.5</td>\n",
       "      <td>83.99</td>\n",
       "      <td>54.61</td>\n",
       "      <td>72.64</td>\n",
       "      <td>36.62</td>\n",
       "      <td>31.68</td>\n",
       "      <td>50.75</td>\n",
       "      <td>96.37</td>\n",
       "      <td>54.62</td>\n",
       "      <td>87.49</td>\n",
       "      <td>73.76</td>\n",
       "      <td>63.62</td>\n",
       "      <td>36.81</td>\n",
       "      <td>80.30</td>\n",
       "      <td>85.47</td>\n",
       "      <td>86.42</td>\n",
       "      <td>31.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>w/ benign token</td>\n",
       "      <td>82.57</td>\n",
       "      <td>52.70</td>\n",
       "      <td>66.98</td>\n",
       "      <td>36.20</td>\n",
       "      <td>30.74</td>\n",
       "      <td>44.27</td>\n",
       "      <td>95.18</td>\n",
       "      <td>50.94</td>\n",
       "      <td>86.59</td>\n",
       "      <td>72.91</td>\n",
       "      <td>60.63</td>\n",
       "      <td>37.15</td>\n",
       "      <td>76.10</td>\n",
       "      <td>80.97</td>\n",
       "      <td>82.02</td>\n",
       "      <td>29.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>w/ sticky oken</td>\n",
       "      <td>82.31</td>\n",
       "      <td>51.98</td>\n",
       "      <td>67.62</td>\n",
       "      <td>35.93</td>\n",
       "      <td>31.06</td>\n",
       "      <td>43.36</td>\n",
       "      <td>94.95</td>\n",
       "      <td>50.99</td>\n",
       "      <td>86.61</td>\n",
       "      <td>73.70</td>\n",
       "      <td>61.31</td>\n",
       "      <td>37.05</td>\n",
       "      <td>77.80</td>\n",
       "      <td>80.11</td>\n",
       "      <td>81.72</td>\n",
       "      <td>30.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  Banking77Classification  \\\n",
       "0               sentence-t5-base                    76.60   \n",
       "1                w/ benign token                    75.73   \n",
       "2                 w/ sticky oken                    75.20   \n",
       "3                   UAE-Large-V1                    87.73   \n",
       "4                w/ benign token                    86.09   \n",
       "5                 w/ sticky oken                    86.56   \n",
       "6                        e5-base                    76.27   \n",
       "7                w/ benign token                    74.85   \n",
       "8                 w/ sticky oken                    75.13   \n",
       "9               gte-base-en-v1.5                    86.72   \n",
       "10               w/ benign token                    84.44   \n",
       "11                w/ sticky oken                    85.87   \n",
       "12  sup-simcse-bert-base-uncased                    75.49   \n",
       "13               w/ benign token                    71.42   \n",
       "14                w/ sticky oken                    72.40   \n",
       "15             all-mpnet-base-v2                    81.70   \n",
       "16               w/ benign token                    79.70   \n",
       "17                w/ sticky oken                    79.64   \n",
       "18               instructor-base                    76.92   \n",
       "19               w/ benign token                    75.07   \n",
       "20                w/ sticky oken                    76.37   \n",
       "21              bge-base-en-v1.5                    83.99   \n",
       "22               w/ benign token                    82.57   \n",
       "23                w/ sticky oken                    82.31   \n",
       "\n",
       "    EmotionClassification  MassiveIntentClassification  BiorxivClusteringS2S  \\\n",
       "0                   51.34                        69.70                 23.11   \n",
       "1                   51.30                        66.57                 20.04   \n",
       "2                   50.20                        66.83                 15.02   \n",
       "3                   51.72                        76.24                 37.24   \n",
       "4                   48.16                        72.13                 35.79   \n",
       "5                   50.43                        72.79                 35.98   \n",
       "6                   51.85                        66.65                 29.92   \n",
       "7                   49.91                        63.00                 28.94   \n",
       "8                   49.30                        61.91                 27.02   \n",
       "9                   46.34                        77.67                 37.39   \n",
       "10                  44.26                        70.36                 36.11   \n",
       "11                  46.10                        74.92                 36.31   \n",
       "12                  45.69                        67.21                 25.70   \n",
       "13                  43.49                        60.38                 25.11   \n",
       "14                  43.34                        61.03                 24.80   \n",
       "15                  42.23                        69.76                 34.82   \n",
       "16                  40.01                        64.10                 33.93   \n",
       "17                  40.65                        65.02                 34.05   \n",
       "18                  48.48                        66.00                 26.40   \n",
       "19                  45.79                        62.38                 18.05   \n",
       "20                  47.66                        64.62                 26.05   \n",
       "21                  54.61                        72.64                 36.62   \n",
       "22                  52.70                        66.98                 36.20   \n",
       "23                  51.98                        67.62                 35.93   \n",
       "\n",
       "    MedrxivClusteringS2S  TwentyNewsgroupsClustering  \\\n",
       "0                  26.03                       49.27   \n",
       "1                  25.06                       37.17   \n",
       "2                  20.41                       35.38   \n",
       "3                  31.18                       51.72   \n",
       "4                  30.96                       40.48   \n",
       "5                  30.94                       47.20   \n",
       "6                  27.67                       43.75   \n",
       "7                  26.51                       22.15   \n",
       "8                  24.92                       20.00   \n",
       "9                  32.31                       48.66   \n",
       "10                 31.03                       20.20   \n",
       "11                 32.01                       44.68   \n",
       "12                 25.85                       31.67   \n",
       "13                 25.19                       28.40   \n",
       "14                 25.17                       29.22   \n",
       "15                 33.42                       50.07   \n",
       "16                 32.55                       39.20   \n",
       "17                 32.16                       39.28   \n",
       "18                 28.38                       52.77   \n",
       "19                 23.13                       28.64   \n",
       "20                 26.55                       50.55   \n",
       "21                 31.68                       50.75   \n",
       "22                 30.74                       44.27   \n",
       "23                 31.06                       43.36   \n",
       "\n",
       "    SprintDuplicateQuestions  StackOverflowDupQuestions  SciDocsRR  SciFact  \\\n",
       "0                      91.23                      48.46      73.96    45.76   \n",
       "1                      87.86                      44.85      72.05    44.58   \n",
       "2                      88.39                      45.16      71.17    26.76   \n",
       "3                      97.24                      55.32      87.49    73.91   \n",
       "4                      96.23                      50.44      86.75    74.51   \n",
       "5                      96.52                      52.44      86.94    72.63   \n",
       "6                      94.19                      48.18      81.01    71.88   \n",
       "7                      91.37                      44.11      79.85    71.36   \n",
       "8                      91.53                      44.80      80.03    70.95   \n",
       "9                      95.03                      52.18      85.16    76.79   \n",
       "10                     89.97                      46.16      83.77    75.41   \n",
       "11                     94.19                      50.00      84.67    73.36   \n",
       "12                     81.74                      40.32      71.14    33.89   \n",
       "13                     76.54                      37.34      70.02    33.66   \n",
       "14                     76.51                      38.31      70.25    29.89   \n",
       "15                     90.15                      51.98      88.65    65.57   \n",
       "16                     86.24                      47.33      87.77    65.14   \n",
       "17                     85.87                      47.79      87.77    64.81   \n",
       "18                     92.06                      50.66      79.36    57.88   \n",
       "19                     88.39                      47.66      77.92    57.70   \n",
       "20                     91.30                      49.67      76.63    43.47   \n",
       "21                     96.37                      54.62      87.49    73.76   \n",
       "22                     95.18                      50.94      86.59    72.91   \n",
       "23                     94.95                      50.99      86.61    73.70   \n",
       "\n",
       "    ArguAna  NFCorpus  SICK-R  STS16  STSBenchmark  SummEval  \n",
       "0     44.84     28.64   80.18  84.03         85.52     31.39  \n",
       "1     45.41     28.48   76.72  79.69         81.32     30.32  \n",
       "2     42.14     13.65   76.32  79.26         81.24     30.84  \n",
       "3     66.15     37.61   82.62  86.61         89.06     32.03  \n",
       "4     63.67     37.70   80.72  80.43         84.23     31.99  \n",
       "5     63.48     37.79   81.53  83.13         86.00     30.84  \n",
       "6     53.03     37.09   80.66  84.49         86.35     31.04  \n",
       "7     51.13     37.15   76.01  78.17         79.42     30.76  \n",
       "8     49.14     37.01   77.17  77.68         80.19     29.99  \n",
       "9     63.65     35.85   79.38  85.02         86.06     31.35  \n",
       "10    61.58     35.77   74.85  76.96         78.49     30.46  \n",
       "11    62.14     35.22   77.36  81.75         83.65     31.87  \n",
       "12    39.56     13.49   80.62  80.71         82.69     31.17  \n",
       "13    36.79     13.45   77.53  75.82         78.32     30.76  \n",
       "14    38.38      8.84   77.74  77.05         79.53     30.18  \n",
       "15    46.52     33.29   80.59  80.03         83.42     27.49  \n",
       "16    44.25     33.20   77.80  68.13         74.11     28.30  \n",
       "17    43.98     33.16   78.04  68.20         73.19     26.17  \n",
       "18    51.18     30.76   80.02  84.78         85.85     30.57  \n",
       "19    47.45     29.77   75.48  77.97         79.99     30.37  \n",
       "20    47.03     23.11   78.86  81.96         84.21     29.17  \n",
       "21    63.62     36.81   80.30  85.47         86.42     31.04  \n",
       "22    60.63     37.15   76.10  80.97         82.02     29.97  \n",
       "23    61.31     37.05   77.80  80.11         81.72     30.31  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd.iloc[:, 1:] = result_pd.iloc[:, 1:].applymap(lambda x: round(x * 100, 2) if pd.notnull(x) else x)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_excel(\"result.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stickytoken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
