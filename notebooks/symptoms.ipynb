{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXP:\n",
    "    MODEL = '/root/autodl-fs/hf-checkpoints/sentence-transformers/sentence-t5-base'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/BAAI/bge-base-en-v1.5'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/Alibaba-NLP/gte-base-en-v1.5'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/hkunlp/instructor-base'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/princeton-nlp/sup-simcse-bert-base-uncased'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/WhereIsAI/UAE-Large-V1'\n",
    "    # MODEL = '/root/autodl-fs/hf-checkpoints/intfloat/e5-base'\n",
    "    # MODEL = 'Alibaba-NLP/gte-base-en-v1.5'\n",
    "    # MODEL = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "    # MODEL = 'intfloat/e5-mistral-7b-instruct'\n",
    "    # MODEL = 'BAAI/bge-base-en-v1.5'\n",
    "    # MODEL = \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    "    # MODEL = \"Alibaba-NLP/gte-Qwen2-7B-instruct\"\n",
    "    # MODEL = \"princeton-nlp/sup-simcse-bert-large-uncased\"\n",
    "    # MODEL = \"Salesforce/SFR-Embedding-2_R\"\n",
    "    # MODEL = \"nomic-ai/nomic-embed-text-v1\"\n",
    "    # MODEL = \"hkunlp/instructor-base\"\n",
    "    # MODEL = \"hkunlp/instructor-xl\"\n",
    "    # MODEL = \"WhereIsAI/UAE-Large-V1\"\n",
    "    # MODEL = \"nomic-ai/nomic-bert-2048\"\n",
    "    # MODEL = \"thenlper/gte-small\"\n",
    "    # MODEL = \"Salesforce/SFR-Embedding-2_R\"\n",
    "    # MODEL = \"GritLM/GritLM-7B\"\n",
    "    # MODEL = \"sentence-transformers/gtr-t5-base\"\n",
    "    # MODEL = \"nomic-ai/nomic-embed-text-v1.5\"\n",
    "    # MODEL = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    # MODEL  = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    DATASET = [\n",
    "        \"mteb/sts13-sts\",\n",
    "        \"mteb/sts22-crosslingual-sts\",\n",
    "        \"mteb/sts12-sts\",\n",
    "        \"mteb/stsbenchmark-sts\",\n",
    "        \"mteb/sickr-sts\",\n",
    "        \"mteb/sts14-sts\",\n",
    "        \"mteb/biosses-sts\",\n",
    "        \"mteb/sts16-sts\",\n",
    "        \"mteb/sts15-sts\",\n",
    "        \"mteb/stsb_multi_mt\",\n",
    "        \"mteb/sts17-crosslingual-sts\"\n",
    "    ]\n",
    "    SENT_PAIR_NUM = 5\n",
    "    INSERT_NUM = 8\n",
    "    VERIFICATION_SENT_PAIR_NUM = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import sys\n",
    "sys.path.append('/root/StickyToken')\n",
    "# from stickytoken.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stickytoken.embedding_model import ModelAnalyzer\n",
    "moda = ModelAnalyzer(EXP.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stickytoken.sentence_pair import SentencePair,Dataset\n",
    "sent_pairs = SentencePair(EXP.DATASET,moda.model,moda.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sentence_pairs_df = pd.read_csv(sent_pairs.sentence_pairs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs_df = sentence_pairs_df[sentence_pairs_df['sentence2'].apply(lambda x: len(moda.tokenizer.tokenize(x)) >= 30 and len(moda.tokenizer.tokenize(x)) <= 100)]\n",
    "sentence_pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算相似度范围\n",
    "min_similarity = sentence_pairs_df['similarity'].min()\n",
    "max_similarity = sentence_pairs_df['similarity'].max()\n",
    "min_similarity,max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从最小相似度开始，每隔0.01的similarity取一个样本采样\n",
    "similarity_step = 0.01\n",
    "\n",
    "# 进行采样\n",
    "sampled_df = pd.DataFrame()\n",
    "selected_pairs = set()\n",
    "current_similarity = min_similarity\n",
    "while current_similarity <= max_similarity:\n",
    "    sorted_indices = (sentence_pairs_df['similarity'] - current_similarity).abs().argsort()\n",
    "    for idx in sorted_indices:\n",
    "        candidate_row = sentence_pairs_df.iloc[[idx]]\n",
    "        candidate_pair = (candidate_row['sentence1'].values[0], candidate_row['sentence2'].values[0])\n",
    "        if candidate_pair not in selected_pairs:\n",
    "            sampled_df = pd.concat([sampled_df, candidate_row])\n",
    "            selected_pairs.add(candidate_pair)\n",
    "            break\n",
    "    current_similarity += similarity_step\n",
    "\n",
    "# 升序排序\n",
    "sampled_df = sampled_df.sort_values('similarity', ascending=True)\n",
    "\n",
    "# 统计总共使用了多少个不重复的单个句子\n",
    "unique_sentences = set(sampled_df['sentence1']).union(set(sampled_df['sentence2']))\n",
    "print(f\"总共使用了 {len(unique_sentences)} 个不重复的句子。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remained_df = sampled_df.copy()\n",
    "sampled_df = sampled_df.sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((49947 in sampled_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# 从benign_tokens中随机选择一个token作为benigntoken\n",
    "benig_ntoken = random.choice(moda.vocab)\n",
    "benig_ntoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# token = '</s>'\n",
    "token = 'lucrarea'\n",
    "# token = benig_ntoken\n",
    "add_num = 30  # 假设add_num为3，可以根据需要调整\n",
    "\n",
    "from stickytoken.utils import *\n",
    "\n",
    "def modify_text(text, token, num, mode='prefix'):\n",
    "            \"\"\"\n",
    "            根据指定模式修改文本\n",
    "            \n",
    "            参数:\n",
    "            text (str): 原始文本\n",
    "            token (str): 要插入的token\n",
    "            num (int): 插入次数\n",
    "            mode (str): 修改模式，可选 'prefix'|'suffix'|'insert'\n",
    "            \n",
    "            返回:\n",
    "            list: 修改后的文本列表\n",
    "            \"\"\"\n",
    "            if mode == 'prefix':\n",
    "                return [token * i + text for i in range(1, num + 1)]\n",
    "            elif mode == 'suffix':\n",
    "                return [text + token * i for i in range(1, num + 1)]\n",
    "            elif mode == 'insert':\n",
    "                modified_texts = []\n",
    "                temp_text = text\n",
    "                for _ in range(num):\n",
    "                    new_text = random_insert(temp_text, token, 1)\n",
    "                    temp_text = new_text\n",
    "                    modified_texts.append(new_text)\n",
    "                return modified_texts\n",
    "            else:\n",
    "                raise ValueError(\"Invalid mode. Choose from 'prefix', 'suffix', or 'insert'\")\n",
    "\n",
    "# 使用modify_text函数对sentence2列进行修改\n",
    "sampled_df['sentence2_list_suffix'] = sampled_df['sentence2'].apply(lambda x: modify_text(x, token, add_num, mode='suffix'))\n",
    "sampled_df['sentence2_list_prefix'] = sampled_df['sentence2'].apply(lambda x: modify_text(x, token, add_num, mode='prefix'))\n",
    "sampled_df['sentence2_list_insert'] = sampled_df['sentence2'].apply(lambda x: modify_text(x, token, add_num, mode='insert'))\n",
    "\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个sentence1和sentence2列表中每个句子的余弦相似度\n",
    "def calculate_similarity(row, input_col='sentence2_list_suffix'):\n",
    "    sentence1 = row['sentence1']\n",
    "    sentence2_list = row[input_col]\n",
    "    similarities = []\n",
    "    for sentence2 in sentence2_list:\n",
    "        embeddings = moda.model.encode([sentence1, sentence2])\n",
    "        cosine_sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        similarities.append(cosine_sim)\n",
    "    return similarities\n",
    "\n",
    "# 更新similarity列\n",
    "sampled_df['similarity_list_suffix'] = sampled_df.apply(calculate_similarity, axis=1)\n",
    "sampled_df['similarity_list_prefix'] = sampled_df.apply(calculate_similarity, input_col='sentence2_list_prefix', axis=1)\n",
    "sampled_df['similarity_list_insert'] = sampled_df.apply(calculate_similarity, input_col='sentence2_list_insert', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['similarity_list'] = sampled_df[\"similarity_list_suffix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sampled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# plt.rcParams['font.family'] = 'sans-serif'\n",
    "# 设置全局字体样式\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'font.weight': 'normal',\n",
    "    'axes.labelweight': 'normal',\n",
    "    'axes.titleweight': 'normal',\n",
    "})\n",
    "\n",
    "# 准备绘图数据\n",
    "all_similarity_values = [val for sublist in df['similarity_list'] for val in sublist]\n",
    "first_similarity_values = [lst[0] for lst in df['similarity_list']]\n",
    "final_similarity_values = [lst[-1] for lst in df['similarity_list']]\n",
    "\n",
    "# 设置颜色映射\n",
    "norm = plt.Normalize(min(first_similarity_values), 1)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "\n",
    "# 创建绘图\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 6), gridspec_kw={\"width_ratios\": [4, 0.5], \"wspace\": 0.1})\n",
    "line_ax, box_ax = axes\n",
    "\n",
    "# 折线图\n",
    "for idx, row in df.iterrows():\n",
    "    line_ax.plot(row['similarity_list'], color=sm.to_rgba(row['similarity_list'][0]), alpha=0.7)\n",
    "\n",
    "line_ax.set_xlabel(\"Inserted number of sticky token\", fontsize=16)\n",
    "line_ax.set_ylabel(\"Cosine similarity\", fontsize=16)\n",
    "line_ax.grid(True, linestyle='--')\n",
    "line_ax.set_xticks(range(0, len(df.iloc[0]['similarity_list']), 2))\n",
    "line_ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# 箱线图\n",
    "sns.boxplot(y=final_similarity_values, ax=box_ax, color=\"skyblue\", width=0.3, fliersize=0,  linewidth=0.8)\n",
    "box_ax.set_xticklabels([])\n",
    "box_ax.set_yticklabels([''] * len(box_ax.get_yticks()))\n",
    "box_ax.grid(True, axis=\"y\", linestyle='--')\n",
    "box_ax.set_ylim(line_ax.get_ylim())\n",
    "box_ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# 添加颜色条并调小\n",
    "# cbar = fig.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", label=\"Initial Similarity\")\n",
    "# cbar_ax.set_position([0.85, 0.38, 0.02, 0.5])\n",
    "# cbar.ax.tick_params(labelsize=14)\n",
    "# cbar.set_label(\"Initial Similarity\", fontsize=16)\n",
    "\n",
    "# 高质量保存\n",
    "plt.savefig(r'/root/StickyToken/fig/sticky_symptoms_add.pdf', \n",
    "            format='pdf', \n",
    "            dpi=300, \n",
    "            bbox_inches='tight', \n",
    "            pad_inches=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'font.weight': 'normal',\n",
    "    'axes.labelweight': 'normal',\n",
    "    'axes.titleweight': 'normal',\n",
    "})\n",
    "\n",
    "def plot_similarity(token, sampled_df, add_num=40, similarity_list_col='similarity_list',\n",
    "                    save_path='/root/StickyToken/fig/sticky_symptoms_add.pdf',\n",
    "                    color = 'blue',\n",
    "                    format='pdf',\n",
    "                    font_size=22):\n",
    "    \"\"\"\n",
    "    绘制相似度变化图\n",
    "    :param token: 要添加的token\n",
    "    :param sampled_df: 包含句子和相似度数据的DataFrame\n",
    "    :param save_path: 图片保存路径\n",
    "    \"\"\"\n",
    "    sampled_df = sampled_df.copy()[['sentence1', 'sentence2', 'similarity']]\n",
    "    sampled_df['sentence2_list_suffix'] = sampled_df['sentence2'].apply(lambda x: [x + token * i for i in range(0, add_num + 1)])\n",
    "\n",
    "    sampled_df[similarity_list_col] = sampled_df.apply(calculate_similarity, axis=1)\n",
    "    # 准备绘图数据\n",
    "    all_similarity_values = [val for sublist in sampled_df[similarity_list_col] for val in sublist]\n",
    "    first_similarity_values = [lst[0] for lst in sampled_df[similarity_list_col]]\n",
    "    final_similarity_values = [lst[-1] for lst in sampled_df[similarity_list_col]]\n",
    "\n",
    "    # 设置颜色映射\n",
    "    norm = plt.Normalize(min(first_similarity_values), 1)\n",
    "    if color == 'blue':\n",
    "        sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "    elif color == 'red':\n",
    "        sm = plt.cm.ScalarMappable(cmap='magma', norm=norm)  # 使用黄红渐变色系\n",
    "\n",
    "    # 创建绘图\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9, 6), gridspec_kw={\"width_ratios\": [4, 0.5], \"wspace\": 0.1})\n",
    "    line_ax, box_ax = axes\n",
    "\n",
    "    # 创建颜色条轴\n",
    "    cbar_ax = fig.add_axes([0.85, 0.38, 0.02, 0.5])\n",
    "\n",
    "    # 折线图\n",
    "    for idx, row in sampled_df.iterrows():\n",
    "        line_ax.plot(row[similarity_list_col], color=sm.to_rgba(row[similarity_list_col][0]), alpha=0.7)\n",
    "\n",
    "    if color == 'blue':\n",
    "        line_ax.set_xlabel(\"Inserted number of random token\", fontsize=font_size)\n",
    "    elif color == 'red':\n",
    "        line_ax.set_xlabel(\"Inserted number of sticky token\", fontsize=font_size)\n",
    "    line_ax.set_ylabel(\"Cosine similarity\", fontsize=font_size)\n",
    "    line_ax.grid(True, linestyle='--')\n",
    "    line_ax.set_xticks(range(0, len(sampled_df.iloc[0][similarity_list_col]), 3))\n",
    "    line_ax.set_xlim(0, len(sampled_df.iloc[0][similarity_list_col]))\n",
    "    line_ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "    # 箱线图\n",
    "    if color == 'blue':\n",
    "        sns.boxplot(y=final_similarity_values, ax=box_ax, color=\"skyblue\", width=0.3, fliersize=0, linewidth=0.8)\n",
    "    elif color == 'red':\n",
    "        sns.boxplot(y=final_similarity_values, ax=box_ax, color=\"#D6AFB9\", width=0.3, fliersize=0, linewidth=0.8) \n",
    "    box_ax.set_xticklabels([])\n",
    "    box_ax.set_yticklabels([''] * len(box_ax.get_yticks()))\n",
    "    box_ax.grid(True, axis=\"y\", linestyle='--')\n",
    "    box_ax.set_ylim(line_ax.get_ylim())\n",
    "    box_ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "    # 添加颜色条并调小，使用Reds颜色映射\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", label=\"Initial Similarity\", cmap=\"Reds\")\n",
    "    cbar.ax.tick_params(labelsize=16)\n",
    "    cbar.set_label(\"Initial Similarity\", fontsize=font_size)\n",
    "    \n",
    "    # 设置整体图的标题\n",
    "    # fig.suptitle(f'Add Token: {token}', fontsize=16, y=0.95)\n",
    "    \n",
    "    # 高质量保存\n",
    "    plt.savefig(save_path, \n",
    "                format=format, \n",
    "                dpi=300, \n",
    "                bbox_inches='tight', \n",
    "                pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_sticky_token_list(model_name):\n",
    "    sticky_tokens_of_all_models_df = pd.read_csv(\"../results/final_all_models_sticky_tokens.csv\")\n",
    "    # 先筛选出对应模型的行\n",
    "    sticky_token_column = sticky_tokens_of_all_models_df[sticky_tokens_of_all_models_df['model'] == model_name]\n",
    "    # 按照main_metric从高到低排序\n",
    "    sticky_token_column = sticky_token_column.sort_values(by='main_metric', ascending=False)\n",
    "    # 获取排序后的raw_vocab列表\n",
    "    sticky_token_list = sticky_token_column['raw_vocab'].to_list()\n",
    "    return sticky_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticky_tokens = get_sticky_token_list(moda.model_name)\n",
    "sticky_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sticky_token in sticky_tokens:\n",
    "    # 处理包含\"/\"的token，将其替换为\"_\"\n",
    "    safe_token = sticky_token.replace(\"/\", \"_\")\n",
    "    save_path = f'/root/StickyToken/fig/sticky_symptoms_add/{moda.model_name}+{safe_token}.pdf'\n",
    "    plot_similarity(sticky_token, sampled_df, add_num=30,similarity_list_col='similarity_list_suffix' ,save_path=save_path,color = 'red',format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moda.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# 从benign_tokens中随机选择一个token作为benigntoken\n",
    "benig_ntoken = random.choice(moda.vocab)\n",
    "benig_ntoken = 'and'\n",
    "print(benig_ntoken)\n",
    "plot_similarity(benig_ntoken, sampled_df, add_num=30, save_path='/root/StickyToken/fig/benign_symptoms_add.pdf',color = 'blue',format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "random.seed(42)\n",
    "# 随机选择100个benign_token\n",
    "benign_tokens = random.choices(moda.vocab, k=100)\n",
    "\n",
    "for i, benign_token in tqdm(enumerate(benign_tokens), total=len(benign_tokens), desc=\"Processing benign tokens\"):\n",
    "    print(f\"benign_token: {benign_token}\")\n",
    "    plot_similarity(benign_token, sampled_df, add_num=30, save_path=f'/root/StickyToken/fig/benign_symptoms_add/benign_symptoms_add_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def random_replace(text, replace_string, times):\n",
    "    tokens = moda.tokenizer.tokenize(text)  # 使用tokenizer将句子分割成token列表\n",
    "    for _ in range(times):\n",
    "        replace_position = random.randint(0, len(tokens) - 1)  # 随机选择替换位置\n",
    "        tokens[replace_position] = replace_string  # 在随机位置替换字符串\n",
    "    return moda.tokenizer.convert_tokens_to_string(tokens)  # 将token列表重新组合成句子\n",
    "\n",
    "# 使用random_replace函数处理'sentence2'列，嵌套调用random_replace，生成新的句子并保存到新的列'sentence2_replaced'\n",
    "def nested_random_replace(text, replace_string, times):\n",
    "    replaced_sentences = [text]\n",
    "    for _ in range(times):\n",
    "        text = random_replace(text, replace_string, 1)  # 每次调用random_replace时times=1\n",
    "        replaced_sentences.append(text)\n",
    "    return replaced_sentences\n",
    "\n",
    "sampled_df['sentence2_replaced'] = sampled_df['sentence2'].apply(lambda x: nested_random_replace(x, token, add_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算'sentence2_replaced'列和'sentence1'列的余弦相似度\n",
    "def calculate_replaced_similarity(row):\n",
    "    sentence1 = row['sentence1']\n",
    "    sentence2_replaced_list = row['sentence2_replaced']\n",
    "    similarities = []\n",
    "    for sentence2_replaced in sentence2_replaced_list:\n",
    "        embeddings = moda.model.encode([sentence1, sentence2_replaced])\n",
    "        cosine_sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "        similarities.append(cosine_sim)\n",
    "    return similarities\n",
    "\n",
    "# 更新similarity_replaced列\n",
    "sampled_df['similarity_replaced_list'] = sampled_df.apply(calculate_replaced_similarity, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sampled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similarity_values = [val for sublist in df['similarity_replaced_list'] for val in sublist]\n",
    "first_similarity_values = [lst[0] for lst in df['similarity_replaced_list']]\n",
    "final_similarity_values = [lst[-1] for lst in df['similarity_replaced_list']]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 设置颜色映射\n",
    "norm = plt.Normalize(min(first_similarity_values), 1)\n",
    "sm = plt.cm.ScalarMappable(cmap='magma', norm=norm)  # 使用magma红黄色系\n",
    "\n",
    "# 创建绘图\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={\"width_ratios\": [4, 0.5], \"wspace\": 0.1})\n",
    "line_ax, box_ax = axes\n",
    "\n",
    "# 折线图\n",
    "for idx, row in df.iterrows():\n",
    "    line_ax.plot(row['similarity_replaced_list'], color=sm.to_rgba(row['similarity_replaced_list'][0]), alpha=0.7)\n",
    "\n",
    "line_ax.set_xlabel(\"Inserted number of sticky token\", fontsize=18)\n",
    "line_ax.set_ylabel(\"Cosine similarity\", fontsize=18)\n",
    "line_ax.grid(True, linestyle='--')\n",
    "line_ax.set_xticks(range(0, len(df.iloc[0]['similarity_replaced_list']), 2))\n",
    "line_ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# 箱线图\n",
    "sns.boxplot(y=final_similarity_values, ax=box_ax, color=\"#D6AFB9\", width=0.3, fliersize=0, linewidth=0.8)  # 使用浅红色\n",
    "box_ax.set_xticklabels([])\n",
    "box_ax.set_yticklabels([''] * len(box_ax.get_yticks()))\n",
    "box_ax.grid(True, axis=\"y\", linestyle='--')\n",
    "box_ax.set_ylim(line_ax.get_ylim())\n",
    "box_ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(r'/root/StickyToken/fig/symptoms_replace.pdf', format='pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stickytoken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
